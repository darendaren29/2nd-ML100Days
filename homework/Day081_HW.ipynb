{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work\n",
    "1. 請比較使用 l1, l1_l2 及不同比例下的訓練結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import keras\n",
    "\n",
    "# Disable GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 資料前處理\n",
    "def preproc_x(x, flatten=True):\n",
    "    x = x / 255.\n",
    "    if flatten:\n",
    "        x = x.reshape((len(x), -1))\n",
    "    return x\n",
    "\n",
    "def preproc_y(y, num_classes=10):\n",
    "    if y.shape[-1] == 1:\n",
    "        y = keras.utils.to_categorical(y, num_classes)\n",
    "    return y    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = train\n",
    "x_test, y_test = test\n",
    "\n",
    "# Preproc the inputs\n",
    "x_train = preproc_x(x_train)\n",
    "x_test = preproc_x(x_test)\n",
    "\n",
    "# Preprc the outputs\n",
    "y_train = preproc_y(y_train)\n",
    "y_test = preproc_y(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.regularizers import l1, l2, l1_l2\n",
    "def build_mlp(input_shape, output_units=10, num_neurons=[512, 256, 128], l1_ratio=1e-2):\n",
    "    input_layer = keras.layers.Input(input_shape)\n",
    "    \n",
    "    for i, n_units in enumerate(num_neurons):\n",
    "        if i == 0:\n",
    "            x = keras.layers.Dense(units=n_units, \n",
    "                                   activation=\"relu\", \n",
    "                                   name=\"hidden_layer\"+str(i+1), \n",
    "                                   kernel_regularizer=l1(l1_ratio))(input_layer)\n",
    "        else:\n",
    "            x = keras.layers.Dense(units=n_units, \n",
    "                                   activation=\"relu\", \n",
    "                                   name=\"hidden_layer\"+str(i+1),\n",
    "                                   kernel_regularizer=l1(l1_ratio))(x)\n",
    "    \n",
    "    out = keras.layers.Dense(units=output_units, activation=\"softmax\", name=\"output\")(x)\n",
    "    \n",
    "    model = keras.models.Model(inputs=[input_layer], outputs=[out])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Code Here\n",
    "設定超參數\n",
    "\"\"\"\n",
    "LEARNING_RATE = 1e-3\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 256\n",
    "MOMENTUM = 0.95\n",
    "L1_EXP = [1e-2, 1e-4, 1e-8, 1e-12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment with Regulizer = 0.010000\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 198.6385 - acc: 0.2397 - val_loss: 41.0906 - val_acc: 0.2613\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 19.0998 - acc: 0.1184 - val_loss: 7.2646 - val_acc: 0.1000\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 4.1026 - acc: 0.1002 - val_loss: 2.6472 - val_acc: 0.1000\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 2.4862 - acc: 0.0986 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 2.4626 - acc: 0.0975 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 2.4626 - acc: 0.0982 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.4626 - acc: 0.0964 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 2.4626 - acc: 0.0979 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 2.4626 - acc: 0.0976 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 2.4626 - acc: 0.0988 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 2.4626 - acc: 0.0966 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 2.4626 - acc: 0.0974 - val_loss: 2.4624 - val_acc: 0.1000\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 2.4626 - acc: 0.0983 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 2.4626 - acc: 0.0959 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 2.4626 - acc: 0.0982 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 2.4626 - acc: 0.0973 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 2.4626 - acc: 0.0980 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 2.4626 - acc: 0.0972 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 2.4626 - acc: 0.0949 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 2.4626 - acc: 0.0979 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 2.4626 - acc: 0.0998 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 2.4626 - acc: 0.0986 - val_loss: 2.4624 - val_acc: 0.1000\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 2.4626 - acc: 0.0983 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 2.4626 - acc: 0.0980 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 2.4626 - acc: 0.0984 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.4626 - acc: 0.0976 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 2.4626 - acc: 0.0991 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 2.4626 - acc: 0.0979 - val_loss: 2.4624 - val_acc: 0.1000\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 2.4626 - acc: 0.1000 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 2.4626 - acc: 0.0989 - val_loss: 2.4624 - val_acc: 0.1000\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 2.4626 - acc: 0.0995 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 2.4626 - acc: 0.0980 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 2.4626 - acc: 0.0990 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.4626 - acc: 0.0986 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 2.4626 - acc: 0.0991 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.4626 - acc: 0.0977 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 2.4626 - acc: 0.0988 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 2.4626 - acc: 0.0997 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 2.4626 - acc: 0.0985 - val_loss: 2.4624 - val_acc: 0.1000\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 2.4626 - acc: 0.0965 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 2.4626 - acc: 0.0971 - val_loss: 2.4627 - val_acc: 0.1000\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 2.4626 - acc: 0.0972 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 2.4626 - acc: 0.0983 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 2.4626 - acc: 0.0975 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 2.4626 - acc: 0.0972 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 2.4626 - acc: 0.0978 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 2.4626 - acc: 0.0971 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 48/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 2s 41us/step - loss: 2.4626 - acc: 0.0970 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 2.4626 - acc: 0.0976 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 2.4626 - acc: 0.0981 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Experiment with Regulizer = 0.000100\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 6.0189 - acc: 0.2651 - val_loss: 5.8165 - val_acc: 0.3496\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 5.7197 - acc: 0.3668 - val_loss: 5.6293 - val_acc: 0.3873\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 5.5665 - acc: 0.3977 - val_loss: 5.5114 - val_acc: 0.4101\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 5.4422 - acc: 0.4181 - val_loss: 5.3893 - val_acc: 0.4258\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 5.3324 - acc: 0.4353 - val_loss: 5.3089 - val_acc: 0.4279\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 5.2324 - acc: 0.4495 - val_loss: 5.1982 - val_acc: 0.4468\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 5.1390 - acc: 0.4596 - val_loss: 5.1085 - val_acc: 0.4557\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 5.0502 - acc: 0.4690 - val_loss: 5.0276 - val_acc: 0.4641\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 4.9639 - acc: 0.4780 - val_loss: 4.9504 - val_acc: 0.4708\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 4.8790 - acc: 0.4868 - val_loss: 4.8710 - val_acc: 0.4743\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 4.7983 - acc: 0.4949 - val_loss: 4.8029 - val_acc: 0.4727\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 4.7197 - acc: 0.5000 - val_loss: 4.7549 - val_acc: 0.4777\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 4.6429 - acc: 0.5075 - val_loss: 4.6638 - val_acc: 0.4853\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 4.5684 - acc: 0.5144 - val_loss: 4.5958 - val_acc: 0.4941\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 4.4938 - acc: 0.5219 - val_loss: 4.5149 - val_acc: 0.4959\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 4.4215 - acc: 0.5238 - val_loss: 4.4467 - val_acc: 0.5011\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 4.3516 - acc: 0.5312 - val_loss: 4.3909 - val_acc: 0.4998\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 4.2817 - acc: 0.5348 - val_loss: 4.3770 - val_acc: 0.4814\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 4.2125 - acc: 0.5413 - val_loss: 4.2643 - val_acc: 0.5086\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 4.1468 - acc: 0.5459 - val_loss: 4.2019 - val_acc: 0.5092\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 4.0796 - acc: 0.5503 - val_loss: 4.1493 - val_acc: 0.5155\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 4.0155 - acc: 0.5528 - val_loss: 4.0979 - val_acc: 0.5140\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 3.9541 - acc: 0.5551 - val_loss: 4.0372 - val_acc: 0.5121\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 3.8903 - acc: 0.5643 - val_loss: 3.9789 - val_acc: 0.5207\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 3.8297 - acc: 0.5662 - val_loss: 3.9644 - val_acc: 0.5095\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 3.7733 - acc: 0.5699 - val_loss: 3.8759 - val_acc: 0.5120\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 3.7134 - acc: 0.5745 - val_loss: 3.8375 - val_acc: 0.5112\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 3.6552 - acc: 0.5773 - val_loss: 3.8399 - val_acc: 0.5032\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 3.5987 - acc: 0.5788 - val_loss: 3.7405 - val_acc: 0.5242\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 3.5445 - acc: 0.5840 - val_loss: 3.6935 - val_acc: 0.5170\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 3.4863 - acc: 0.5867 - val_loss: 3.6877 - val_acc: 0.5099\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 3.4323 - acc: 0.5896 - val_loss: 3.5809 - val_acc: 0.5262\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 3.3827 - acc: 0.5921 - val_loss: 3.5548 - val_acc: 0.5203\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 3.3274 - acc: 0.5998 - val_loss: 3.5259 - val_acc: 0.5149\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 3.2812 - acc: 0.5984 - val_loss: 3.4596 - val_acc: 0.5245\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 3.2295 - acc: 0.6016 - val_loss: 3.4186 - val_acc: 0.5219\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 3.1830 - acc: 0.6051 - val_loss: 3.3427 - val_acc: 0.5406\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 3.1334 - acc: 0.6089 - val_loss: 3.3222 - val_acc: 0.5344\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 3.0911 - acc: 0.6074 - val_loss: 3.2732 - val_acc: 0.5292\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 3.0408 - acc: 0.6133 - val_loss: 3.2857 - val_acc: 0.5203\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 2.9947 - acc: 0.6142 - val_loss: 3.2034 - val_acc: 0.5345\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 2.9525 - acc: 0.6180 - val_loss: 3.2633 - val_acc: 0.5005\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 2.9125 - acc: 0.6179 - val_loss: 3.1693 - val_acc: 0.5212\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 2.8734 - acc: 0.6190 - val_loss: 3.1432 - val_acc: 0.5233\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.8241 - acc: 0.6240 - val_loss: 3.0719 - val_acc: 0.5245\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 2.7971 - acc: 0.6198 - val_loss: 3.0735 - val_acc: 0.5182\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 2.7529 - acc: 0.6246 - val_loss: 3.0043 - val_acc: 0.5284\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.7148 - acc: 0.6257 - val_loss: 3.0506 - val_acc: 0.5080\n",
      "Epoch 49/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 2s 41us/step - loss: 2.6759 - acc: 0.6284 - val_loss: 3.0360 - val_acc: 0.4986\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.6337 - acc: 0.6328 - val_loss: 2.9079 - val_acc: 0.5344\n",
      "Experiment with Regulizer = 0.000000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 2.0318 - acc: 0.2769 - val_loss: 1.8669 - val_acc: 0.3477\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 1.8105 - acc: 0.3677 - val_loss: 1.7642 - val_acc: 0.3873\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 1.7255 - acc: 0.3975 - val_loss: 1.6879 - val_acc: 0.4090\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 1.6640 - acc: 0.4186 - val_loss: 1.6450 - val_acc: 0.4264\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 1.6169 - acc: 0.4356 - val_loss: 1.6040 - val_acc: 0.4367\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 1.5750 - acc: 0.4509 - val_loss: 1.5731 - val_acc: 0.4449\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 1.5412 - acc: 0.4621 - val_loss: 1.5540 - val_acc: 0.4512\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 1.5090 - acc: 0.4723 - val_loss: 1.5147 - val_acc: 0.4620\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.4812 - acc: 0.4818 - val_loss: 1.4954 - val_acc: 0.4751\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 1.4543 - acc: 0.4892 - val_loss: 1.4772 - val_acc: 0.4812\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.4276 - acc: 0.4997 - val_loss: 1.4612 - val_acc: 0.4794\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 1.4074 - acc: 0.5077 - val_loss: 1.4431 - val_acc: 0.4927\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 1.3852 - acc: 0.5142 - val_loss: 1.4471 - val_acc: 0.4881\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 1.3664 - acc: 0.5203 - val_loss: 1.4163 - val_acc: 0.4981\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 1.3454 - acc: 0.5274 - val_loss: 1.4231 - val_acc: 0.5008\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 1.3273 - acc: 0.5349 - val_loss: 1.4059 - val_acc: 0.5024\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 1.3095 - acc: 0.5410 - val_loss: 1.4174 - val_acc: 0.4991\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 1.2958 - acc: 0.5442 - val_loss: 1.3788 - val_acc: 0.5123\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.2777 - acc: 0.5503 - val_loss: 1.3758 - val_acc: 0.5118\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 1.2611 - acc: 0.5576 - val_loss: 1.3895 - val_acc: 0.5073\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 1.2454 - acc: 0.5629 - val_loss: 1.3730 - val_acc: 0.5126\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 1.2315 - acc: 0.5671 - val_loss: 1.3734 - val_acc: 0.5115\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.2139 - acc: 0.5730 - val_loss: 1.3952 - val_acc: 0.5109\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 1.2005 - acc: 0.5785 - val_loss: 1.3660 - val_acc: 0.5217\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 1.1849 - acc: 0.5835 - val_loss: 1.3807 - val_acc: 0.5138\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 1.1706 - acc: 0.5889 - val_loss: 1.3982 - val_acc: 0.5079\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 1.1583 - acc: 0.5944 - val_loss: 1.3625 - val_acc: 0.5172\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 1.1443 - acc: 0.5983 - val_loss: 1.3696 - val_acc: 0.5207\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 1.1278 - acc: 0.6020 - val_loss: 1.3385 - val_acc: 0.5297\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 1.1141 - acc: 0.6075 - val_loss: 1.3970 - val_acc: 0.5101\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 1.1034 - acc: 0.6135 - val_loss: 1.3554 - val_acc: 0.5215\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 1.0890 - acc: 0.6175 - val_loss: 1.4129 - val_acc: 0.5099\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 1.0734 - acc: 0.6218 - val_loss: 1.3672 - val_acc: 0.5202\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 1.0640 - acc: 0.6272 - val_loss: 1.3716 - val_acc: 0.5211\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 1.0515 - acc: 0.6309 - val_loss: 1.3830 - val_acc: 0.5192\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 1.0424 - acc: 0.6324 - val_loss: 1.3479 - val_acc: 0.5339\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 1.0287 - acc: 0.6388 - val_loss: 1.4321 - val_acc: 0.5102\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 1.0105 - acc: 0.6454 - val_loss: 1.3610 - val_acc: 0.5296\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 0.9975 - acc: 0.6507 - val_loss: 1.3869 - val_acc: 0.5244\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.9872 - acc: 0.6562 - val_loss: 1.3704 - val_acc: 0.5338\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 0.9761 - acc: 0.6571 - val_loss: 1.3638 - val_acc: 0.5332\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 0.9673 - acc: 0.6617 - val_loss: 1.3811 - val_acc: 0.5289\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 0.9505 - acc: 0.6674 - val_loss: 1.5338 - val_acc: 0.4930\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 0.9404 - acc: 0.6719 - val_loss: 1.3655 - val_acc: 0.5379\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 0.9261 - acc: 0.6771 - val_loss: 1.4644 - val_acc: 0.5184\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 0.9161 - acc: 0.6803 - val_loss: 1.4218 - val_acc: 0.5243\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 0.8967 - acc: 0.6863 - val_loss: 1.4501 - val_acc: 0.5142\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 0.8929 - acc: 0.6869 - val_loss: 1.4081 - val_acc: 0.5285\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 0.8766 - acc: 0.6929 - val_loss: 1.4918 - val_acc: 0.5175\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 2s 42us/step - loss: 0.8668 - acc: 0.6959 - val_loss: 1.3745 - val_acc: 0.5330\n",
      "Experiment with Regulizer = 0.000000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 2s 50us/step - loss: 2.0272 - acc: 0.2786 - val_loss: 1.8535 - val_acc: 0.3483\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 1.7951 - acc: 0.3704 - val_loss: 1.7435 - val_acc: 0.3868\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 1.7097 - acc: 0.4005 - val_loss: 1.6791 - val_acc: 0.4097\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.6510 - acc: 0.4223 - val_loss: 1.6385 - val_acc: 0.4224\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 1.6047 - acc: 0.4362 - val_loss: 1.5890 - val_acc: 0.4412\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 1.5671 - acc: 0.4522 - val_loss: 1.5647 - val_acc: 0.4561\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 1.5330 - acc: 0.4627 - val_loss: 1.5349 - val_acc: 0.4577\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 1.5045 - acc: 0.4714 - val_loss: 1.5234 - val_acc: 0.4652\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 1.4769 - acc: 0.4817 - val_loss: 1.4959 - val_acc: 0.4683\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 1.4507 - acc: 0.4905 - val_loss: 1.4787 - val_acc: 0.4761\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 1.4276 - acc: 0.4996 - val_loss: 1.4882 - val_acc: 0.4746\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 1.4042 - acc: 0.5069 - val_loss: 1.4451 - val_acc: 0.4878\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 1.3818 - acc: 0.5147 - val_loss: 1.4354 - val_acc: 0.4879\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 1.3621 - acc: 0.5219 - val_loss: 1.4199 - val_acc: 0.4955\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.3410 - acc: 0.5287 - val_loss: 1.4139 - val_acc: 0.4981\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 1.3233 - acc: 0.5350 - val_loss: 1.4299 - val_acc: 0.4958\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 1.3061 - acc: 0.5407 - val_loss: 1.4400 - val_acc: 0.4908\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 1.2877 - acc: 0.5481 - val_loss: 1.3825 - val_acc: 0.5102\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 1.2727 - acc: 0.5529 - val_loss: 1.4054 - val_acc: 0.5017\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 1.2563 - acc: 0.5589 - val_loss: 1.3786 - val_acc: 0.5070\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 1.2391 - acc: 0.5638 - val_loss: 1.3642 - val_acc: 0.5174\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 1.2240 - acc: 0.5717 - val_loss: 1.4704 - val_acc: 0.4824\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 1.2100 - acc: 0.5759 - val_loss: 1.3505 - val_acc: 0.5239\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.1959 - acc: 0.5807 - val_loss: 1.3741 - val_acc: 0.5150\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 1.1811 - acc: 0.5853 - val_loss: 1.3644 - val_acc: 0.5172\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 1.1660 - acc: 0.5900 - val_loss: 1.3616 - val_acc: 0.5211\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 1.1516 - acc: 0.5958 - val_loss: 1.3944 - val_acc: 0.5094\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 1.1397 - acc: 0.5979 - val_loss: 1.3604 - val_acc: 0.5243\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 1.1235 - acc: 0.6046 - val_loss: 1.4425 - val_acc: 0.4910\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 1.1109 - acc: 0.6101 - val_loss: 1.3419 - val_acc: 0.5359\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 1.0940 - acc: 0.6157 - val_loss: 1.3683 - val_acc: 0.5232\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 1.0831 - acc: 0.6210 - val_loss: 1.3426 - val_acc: 0.5280\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 1.0684 - acc: 0.6251 - val_loss: 1.3322 - val_acc: 0.5350\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 1.0537 - acc: 0.6324 - val_loss: 1.3392 - val_acc: 0.5338\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 1.0430 - acc: 0.6332 - val_loss: 1.3401 - val_acc: 0.5324\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 1.0275 - acc: 0.6407 - val_loss: 1.3378 - val_acc: 0.5344\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 1.0165 - acc: 0.6429 - val_loss: 1.4228 - val_acc: 0.5169\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 1.0038 - acc: 0.6481 - val_loss: 1.4442 - val_acc: 0.5121\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 0.9925 - acc: 0.6517 - val_loss: 1.3889 - val_acc: 0.5280\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 0.9791 - acc: 0.6569 - val_loss: 1.3970 - val_acc: 0.5209\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 0.9656 - acc: 0.6613 - val_loss: 1.3934 - val_acc: 0.5263\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 0.9589 - acc: 0.6646 - val_loss: 1.3535 - val_acc: 0.5325\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 0.9446 - acc: 0.6689 - val_loss: 1.3435 - val_acc: 0.5387\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 0.9240 - acc: 0.6780 - val_loss: 1.3576 - val_acc: 0.5401\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.9137 - acc: 0.6814 - val_loss: 1.3991 - val_acc: 0.5199\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 0.9038 - acc: 0.6834 - val_loss: 1.4678 - val_acc: 0.5200\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 0.8915 - acc: 0.6890 - val_loss: 1.4469 - val_acc: 0.5184\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 0.8818 - acc: 0.6905 - val_loss: 1.5362 - val_acc: 0.4936\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 0.8699 - acc: 0.6941 - val_loss: 1.4045 - val_acc: 0.5353\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 0.8550 - acc: 0.7014 - val_loss: 1.4555 - val_acc: 0.5223\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\"\"\"Code Here\n",
    "撰寫你的訓練流程並將結果用 dictionary 紀錄\n",
    "\"\"\"\n",
    "for regulizer_ratio in L1_EXP:\n",
    "    keras.backend.clear_session() # 把舊的 Graph 清掉\n",
    "    print(\"Experiment with Regulizer = %.6f\" % (regulizer_ratio))\n",
    "    model = build_mlp(input_shape=x_train.shape[1:], l1_ratio=regulizer_ratio)\n",
    "    model.summary()\n",
    "    optimizer = keras.optimizers.SGD(lr=LEARNING_RATE, nesterov=True, momentum=MOMENTUM)\n",
    "    model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=optimizer)\n",
    "\n",
    "    model.fit(x_train, y_train, \n",
    "              epochs=EPOCHS, \n",
    "              batch_size=BATCH_SIZE, \n",
    "              validation_data=(x_test, y_test), \n",
    "              shuffle=True)\n",
    "    \n",
    "    # Collect results\n",
    "    train_loss = model.history.history[\"loss\"]\n",
    "    valid_loss = model.history.history[\"val_loss\"]\n",
    "    train_acc = model.history.history[\"acc\"]\n",
    "    valid_acc = model.history.history[\"val_acc\"]\n",
    "    \n",
    "    exp_name_tag = \"exp-l2-%s\" % str(regulizer_ratio)\n",
    "    results[exp_name_tag] = {'train-loss': train_loss,\n",
    "                             'valid-loss': valid_loss,\n",
    "                             'train-acc': train_acc,\n",
    "                             'valid-acc': valid_acc}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeMAAAF1CAYAAADbSIJmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOzdd3hUVf748feZyaQXII0SINTQpTdFRATBBqIrFixr3eLK6roult+K7q5fddW1rA1FXVHBjtJr6CUBQodQEkglbTLJzGT6fH5/3BBBgqACoZzX89xnMveee8+5M0k+95x7zrlKRNA0TdM0reGYGroAmqZpmnah08FY0zRN0xqYDsaapmma1sB0MNY0TdO0BqaDsaZpmqY1MB2MNU3TNK2B6WCsaZqmaQ1MB2NNO8sopZYppSqVUmENXRZN084MHYw17SyilEoFhgACXHcG8w05U3lpmnYsHYw17exyB7AO+Ai48/BKpVSEUuplpdRBpVSVUmqVUiqidtslSqk1SimbUipfKXVX7fplSql7jzjGXUqpVUe8F6XUH5VSe4G9teteqz1GtVJqo1JqyBHpzUqpJ5RS+5VS9trtLZVSbyqlXj7yJJRSs5RSfz4dH5CmnY90MNa0s8sdwKe1y5VKqeTa9S8BfYDBQBPgMSColGoFzAPeABKBnsDmn5HfWGAA0KX2fWbtMZoAnwFfKqXCa7c9AtwCXAXEAncDNcD/gFuUUiYApVQCMByY/nNOXNMuZDoYa9pZQil1CdAa+EJENgL7gVtrg9zdwEQRKRSRgIisEREPcBuwWESmi4hPRCpE5OcE4/8TEauIuABE5JPaY/hF5GUgDEirTXsv8JSIZIthS23aDKAKIwAD3AwsE5GSX/mRaNoFQwdjTTt73AksFJHy2vef1a5LAMIxgvOPtTzO+pOVf+QbpdRflFK7apvCbUBcbf4nyut/wITanycA035FmTTtgqM7bWjaWaD2/u9NgFkpdah2dRjQCGgGuIF2wJYf7ZoP9D/OYZ1A5BHvm9aTpu6xbbX3h/+GUcPdISJBpVQloI7Iqx2wvZ7jfAJsV0pdBHQGZh6nTJqm1UPXjDXt7DAWCGDcu+1Zu3QGVmLcR/4AeEUp1by2I9Wg2qFPnwJXKKVuUkqFKKXilVI9a4+5GRinlIpUSrUH7jlBGWIAP1AGhCil/o5xb/iw94F/KKU6KEMPpVQ8gIgUYNxvngZ8fbjZW9O0k6ODsaadHe4EPhSRPBE5dHgB/otxX3gSsA0j4FmBFwCTiORhdKj6S+36zcBFtcf8D+AFSjCakT89QRkWYHQG2wMcxKiNH9mM/QrwBbAQqAamAhFHbP8f0B3dRK1pP5sSkROn0jRNOwGl1KUYzdWpIhJs6PJo2rlE14w1TfvVlFIWYCLwvg7Emvbz6WCsadqvopTqDNgwOpq92sDF0bRzkm6m1jRN07QGpmvGmqZpmtbAdDDWNE3TtAbWYJN+JCQkSGpqakNlr2mapmln1MaNG8tFJLG+bQ0WjFNTU9mwYUNDZa9pmqZpZ5RS6uDxtulmak3TNE1rYDoYa5qmaVoD08FY0zRN0xqYDsaapmma1sB0MNY0TdO0BqaDsaZpmqY1MB2MNU3TNK2B6WCsaZqmaQ1MB2NN0zRNa2A6GGuapmlaAzupYKyUGqWUylZK7VNKTapn+3+UUptrlz1KKdupL6qmaZqmnZ9OODe1UsoMvAmMAAqATKXU9yKy83AaEXn4iPR/AnqdhrJqmqZp2hnh9ZZgt28kPv6qM5LfydSM+wP7RCRHRLzADGDMT6S/BZh+KgqnaZqmaWeS3b6RXbvuZO3aVuzcOZ5AoOaM5HsyT21qAeQf8b4AGFBfQqVUa6ANsPQ42+8H7gdo1arVzyqopmmapp0OwaCPsrKvKSx8g+rqNZjN0TRvfj8tWjyI2Rx5RspwMsFY1bNOjpP2ZuArEQnUt1FEpgBTAPr27Xu8Y2iapmnaaef1llJUNIWiorfxeosID29HbOyrHDhwF0uWxGG1wuuvn5mynEwwLgBaHvE+BSg6TtqbgT/+2kJpmqZp2qkWCLhwODZRXb2e8vI12GyzUMpLUdFI5s2bwjffjKamxrh7qxR07gyBAJjNp79sJxOMM4EOSqk2QCFGwL31x4mUUmlAY2DtKS2hpmmapv1MIkFqavZgt6+nutpYnM6tiPgBKClpxdq19/Lttw/icnWmRw+4/37o3t1YunaFyDPTQg2cRDAWEb9S6kFgAWAGPhCRHUqpZ4ENIvJ9bdJbgBkiopufNU3TtNMmEHDjcGzE6y2pW3y+0qNevd5iAgEHACIxFBf3Y9Wqv7J16wCs1gFcdVVTrr4aHn8ckpMb+IQA1VCxs2/fvrJhw4YGyVvTNE07twQCbqzW+ZSVfUlFxfd1gfYwszkeszkZpZKBJDyepmza1IPPPhtAVlYnYmLM3Hgj3HorDB16Zpqef0wptVFE+ta37WSaqTVN0zTtjAsEXFitCygr+4KKilkEAg5EmpCdfTNz515Dfn5riouTKS9PIBCwHLN/WBhccw08+SSMHg3h4Q1wEidJB2NN0zStwfn9DjyefNzug3g8edhsy+oCMMSzf//NfPbZb1i+fBhxcRauugratjXu60ZGQkTE0T9HR8PFF0NcXEOf2cnRwVjTNE07I/z+ahyOLOz2LNzuHNzuPDyeg7jdefj91qPSKhVPXt7NTJ/+GxYuHEZYmIWxY+G772DECAgNbaCTOE10MNY0TdNOOZ/Pit2+CYdjU92ry7W3brvZHEd4eCvCwlqh1CBKS1uRk9OarVtbsXZtK3bsaI7JZObKK+Hjj+G664za7vlKB2NN0zTtlAgGvRQVvUtBwWu43fvr1oeHpxId3ZumTe/EZOpDRkYv1q1LJisLsrLAWlspNpmgUyfo1Qv+8Ae48UZISGigkznDdDDWNE3TfhWRIKWln5Ob+yRudy5xcZfSvPn9REf3JiamN4WFTZg1C77/HpYvB5/PaGbu3h1uuMEIvr16QY8eZ3Zs79lEB2NN0zTtFxERKisXkZMzCYcji6ioi+jRYz5xcSPZtEnx3ntGAN661UjfqRM8/DBcey0MGACWYztAX7B0MNY0TdN+turqDeTkTMJmW0J4eCpNm35CZuYt/Pe/JhYtguJio9n5kkvgpZeMANyxY0OX+uylg7GmaZp2UoJBD9XV6ygsfJuyss8JBuPZvv1Vpk79HVu3hgEQHw/Dhxvje6+6ynivnZgOxpqmaVq9gkEv1dUZ2Gzp2GzLqKpag4gbrzeSzz//f8yY8SgisQwZAhMmwBVXwEUXGTVi7efRwVjTNE0DjIk3HI4sqqpW1gbf1QSDNQAUFV3E6tW/Y8uWy1BqKJde2ojZs2HQoLN7ZqtzhQ7GmqZpF6DDgddu34jDsRG7fSM1Nbs5/Lh6l6sbWVn3MG/eMLZuvZSOHeO56SZ47DFo3bphy34+0sFY0zTtAuByHcBmW4rNtgy7PZOammwOB97Q0Ob4fH3IzR3PihV9mDlzADZbIj17wk03wUcfQbt2DVr8854Oxpqmaechj+dQ7b3epVRWLsXtzgHAYkkiNnYgJtMtbN/eh/nz+zB3blPsduNeb79+8MgjRhBOS2vgk7iA6GCsaZp2HggGPVRUpLNv31w8nqXADgACgUZUV19Gaemfyc8fTm5uZ1asUBQUGPu1awe33WbM9zxsGDRu3HDncCHTwVjTNO0c5fNZKSmZQ3b29wSD87FYHLhckWzbNoSsrDvYtGk4+/b1JBg0YzJBbKzxFKOBA43gO2IEtGnT0GehgQ7GmqZp5xSXK4dDh75j//7vMZlWYjIFqKxsRmbmbSh1HT16XE6fPuEMG2YE38NLZCQo1dCl145HB2NN07SzVCDgxG7fhN2egdWaSXl5BmZzLgB5ed3YuHESERHXcdllfXn2WRNhYQ1cYO0X08FY0zTtLCAiOJ3bqa5eQ3V1BnZ7Jk7nDiAIQElJa3bt6kdOzkTi469l1Ki2TJhw/j3X90Klg7GmaVoDCQZ9VFWtpLz8OyoqvsftPgCAzxdPTk5/1q27nt27++N09mP48CTGjoWnnoIQ/Z/7vKO/Uk3TtDPI76/Gap1Pefl3WK1z8fttKBWOzTaCOXOeZNas4Rw6lEqvXoqxY42nHHXvru/3nu90MNY0TTsNAgEXbvcB3O4cXK4c3O4cnM7t2GzLEfFhsSTg8Yxl4cIxvP32COz2KAYMgMcfhzFj9CxXFxodjDVN036lYNBPeflMKipm1wVfr7fwqDQmUyQREe2JjX2I5cvH8NprgzlwwEyTJnDPPcbSrVsDnYDW4HQw1jRN+4X8/mqKi6dSUPAaHs9BLJYkIiM70aTJCMLD2xIR0Zbw8LaYTG2ZPz+JDz5QLFgAIsYTjp5/HsaORfeC1nQw1jRN+7lcrlwKC1+nuHgqgYCduLghtG//KgkJ16KUGTAC7qZN8OGH8NlnUFkJKSlGB6zf/lZPtqEdTQdjTdO0kyAiVFevJT//FcrLv0UpE4mJ42nZ8mFiYvrUpSsthU8+MR6usG2bUeu9/nojAA8fDmZzw52DdvbSwVjTtAuey5VLScnHeDzFBINOAoEfFuO9A7/fjs9XQkhIY5o3fwyz+UGs1hYsX24E4JISWL8e5swBvx/694e334abb4ZGjRr6DLWTVeIoYWnuUpbkLqHYUcycW+eckXx1MNY07YIkIths6RQUvEZFxSxAYbHEYzZHYzZHYTJFEQxGUV3dhPLyKA4dimLbtr58//3tlJVF1XvM5s2NoUh33QVdupzR09F+oSp3FcsPLmdJzhKWHljK9tLtADQKb8Sw1GH4Aj4sZstpL4cOxpqmXVACgRpKSj6hoOB1amp2YLEk0KrVEyQm/o7s7BTWr4d164xa7t69xj4mkzHWt3NnuPVWSEqC5OQfXpOTITHRmP9ZO3tVuavYVb6LnWU72Vm2k1V5q8gsyiQoQSJCIrik1SVM6D6B4W2H06tpL8ymM3dPQQdjTdMuCC7XAYqK3qK4+H38/kqio3vSuvWHrF9/M6+9Fs7cueB0GmmbNoVBg4zhRgMHQp8+EB3dsOXXflogGKDaU02Vpwqb24bVZWVPxR52lu2sC8BF9qK69GHmMHo3680TlzzB8LbDGZQyiLCQhuvWroOxpmnnJZ+vkqqqldhsy7DZluNwZAEmYmPHsWvXQ0yffjGLFim8XqNmO2GC0cFqwABo2VLPeHW65FXlsThnMYmRiQxpPYRG4Sd/Q90b8LIqbxXz9s4joyiDSlclNrcNm9uG3Wuvd58oSxSdEztzRdsr6JLQhc6JnemS2IU2jdqc0ZrviehgrGnaecHrLaeqagU223JstuU4nVsBQakwLJaBlJZOZvr03zJrVksCAWOGqwcfhHHjjNqv7uV8egQlSGZhJrP2zGL2ntlsKdlSt02h6NWsF5e1voyhqUMZ0moIjSMaH7X/QdtB5u2bx/x981mSuwSH14HFZKFfi360a9KORuGNiAuLO/o13Hht36Q9KbEpmJTpTJ/2z6ZEpEEy7tu3r2zYsKFB8tY07dxnPOVoG+Xl31FePhOHYxMAJlMEISGDKSoaypo1Q/nmm/4cPBgOGPd8x40zll69dO33dLF77CzKWcTsPbOZs3cOpc5STMrEJa0u4ZoO1zC6w2gqaipYdmAZyw8uZ03+GjwBDwpFz6Y9uSz1MhSKefvmsat8FwCpjVIZ3X40o9qP4vI2lxMdeu7dN1BKbRSRvvVu08FY07RzRTDop7p6NeXlMykv/w63OxejF/RAioquZvXqYXz9dV8KCoznCjZrBpdd9sPSsWMDFv4s5wv42HxoM2vy11BeU45JmVBKoVB1P5uUCYXCH/TXNQ/bPLYffj5iCUqQuLA4RncYzbUdr2VU+1E0iWhSb95uv5uMwgyWHVjGsgPLWJO/BkEY2nooo9uPZnSH0aTFp6HO8asnHYw1TTtnBQIurNYFtXM/z8LvtwJhVFVdwYYNY5gx41r27WsKGEOLDgfeoUOhQwdd+z2eipoK1hasZU3+GlbnryazMBOX3wUYzcfCT8eGKEsUjcIb1bvER8QzrM0wLm558S8aFuTxe4wezpaIX3RuZ6ufCsb6nrGmaWedQKAGq3UepaVfUlExm2DQic/XmOzsq5k1aywrVlyJ2x1NmzZw6aUwaZLx2r79hR18fQEfW0u2UuWpotpTjd1jx+61H/Wz1WVlY/FGdpfvBiDEFELvZr15oM8DDG45mMEtB9MitgVg3AoQBBEhKEEE49WszKd17G1D9mpuKDoYa5p2VggEnFRUzKWs7EsqKuYQDNbg9SawZs1tzJ59I5s3X0bnzhaGDDGmlhwyBFq0aOhSN7ygBFl5cCXTt0/nq51fUeGqqDedSZmICY0hLjyOHsk9uPOiOxnccjB9m/cl0lL/AOnDzdQoMKN7uJ1OOhhrmtZg/P5qKirmUFb2NVbrXIJBFz5fEhkZd/D1179h27ZLGT48hIcegquvhvj4hi7x6eX2u0+q1ikibCzeyPRt0/l8x+cU2guJtEQyJm0MYzuNJTkqmZiwGGLDYokJjSEmLIaIkIhz/p7r+UwHY03Tziifr5KKiu9rA/BCRDz4/U3Jyvotn332G7ZuHULfvmbuugvGjzfGAJ+PRIRcWy5r89fW3bvdWrKVgASIj4gnOTqZptFNSY46+nV/5X5mbJ/BXuteLCYLozuM5qVuL3Ftx2uJCq1/mk7t7KeDsaZpp53XW0Z5+UzKyr7GZluCiB+vtyWbNv2e6dNvYPv2QbRvb+a22+DLL417v+cbp9dJ1qEs1uavZU3BGtbmr6XEWQJAdGg0A1oMYNIlkwg1h3LIcYgSZwmHHIdYX7ieQ45D1PhqAKNz1bA2w3js4scY13nccXsoa+eWkwrGSqlRwGuAGXhfRJ6vJ81NwGRAgC0icuspLKemaeeYYNBHRcUciovfw2qdDwRxu9uRkfEI06ffwO7d/ejUSXHDDcbjBnv2PH86X3kDXraVbCOzKJPMwkwyizLZUbaDoAQBaN+kPSPbjWRwy8EMShlEt6RuJ5wNyuF1cMhxiJjQGJKjz9PmggvYCYOxMp6U/SYwAigAMpVS34vIziPSdAAeBy4WkUqlVNLpKrCmaWc3lyuX4uL3KSz8kECgGLe7OatWTWLGjJvYv78HPXsqbrsNbrjBmITjXOcNeNlRuoOsQ1lsLNpIZlEmW0q24A14AYiPiKdfi36M7TSWfs37MSBlAElRP/9fZHRoNO2bnIdNBhpwcjXj/sA+EckBUErNAMYAO49Icx/wpohUAohI6akuqKZpZy+73cumTd9js00hLm4RwaCJdeuuYvbs+8nKGk3v3iH87nfGzFdt2zZ0aY+1s2wnH2R9gIiQFJVEUlQSiVGJdT8nRSURaYnE6XWypWQLWcVZbCreRNahLLaXbscX9AFGwOzTrA8P9X+Ifi360a95P1IbpeqOU9oJnUwwbgHkH/G+ABjwozQdAZRSqzGasieLyPwfH0gpdT9wP0CrVq1+SXk1TWtAIgE8niIKCg6wc+cBCgoO4HDk0KHDHBo3LsPtbkl6+jM4nXfTvXsK//mP0fwcdhYOGxURlh9czktrXmLO3jmEmkMxK3PdxBc/FmmJxOVz1U2GkRCZQK+mvXh44MP0ataL3s16075J+3NiHmTt7HMywbi+S7ofT80SAnQALgNSgJVKqW4iYjtqJ5EpwBQwZuD62aXVNO2MCQb92GzplJXNpLx8N07nAUJC8jCZ/ADExkKXLmC3N8PlugSX6z6GDRvJ+PFn93hUf9DP1zu/5qW1L7GhaAOJkYk8e9mz/L7f70mITMDpdVJWU0aps7RuKXMa72PDYunVrBe9mvYiJTZF13i1U+ZkgnEB0PKI9ylAUT1p1omID8hVSmVjBOfMU1JKTdPOCJEANttKDh36nEOHvkapMlyuaPbv705JyQDs9vHExaXSqlUq3bql0rNnK8LCwhu62CfF4XUwddNU/rPuPxysOkjH+I68e8273N7j9qOmXYwKjSIqNIrURqkNV1jtgnMywTgT6KCUagMUAjcDP+4pPRO4BfhIKZWA0WydcyoLqmna6SESpLp6LUVFn1Nc/BUmUzFudyRr117DunXjSU4ezeWXRzBqFLRrd/b3eA5KkLyqPLLLs9lTsYfsimyyK7LJLMykylPFJa0u4bVRr3Ft2rW6SVk7a5wwGIuIXyn1ILAA437wByKyQyn1LLBBRL6v3TZSKbUTCAB/FZH652TTNK3B+f1VVFYupaRkASUlczGb8/F6w1i37ioyM8fTvPk1XHddFE88cXbe7wWjF/Oeij3sKN3B9tLt7CrfxZ6KPey17sXtd9eliwmNIS0hjXGdx3F/n/sZmDKwAUutafXTT23StAuASAC7fSNW6wJKShZQU7MOpQI4nTFkZV3Oli030qzZdYwZE8vQoRByFk0H5Av42F+5n51lO9leup0dZUbw3VOxB3/QuH9tUibaNW5HWkIaafHG0jG+I2kJaSRHJet7u9pZQT+1SdMuQG53HpWVi7BaF1JRsZhg0EowqNizpw+ZmZMoLBxJt26DGDvWwuOPg7mB+13Z3Dayy7PZXb7bWCqM133WfXVBV6Fo07gN3ZK6MSZtDN2SutE1sStpCWmEh5wb9641rT46GGvaecLvr8ZmW1YbgBfhcmUDUFXVjDVrrmPDhpG43SMYOTKBiROhe/eGvf/r8rlYnLOYmbtnMn//fIrsP/QLtZgsdIjvQJfELozrNI60hDS6JHahc0JnPf+ydl7SwVjTzlEiAaqrM6isXIjVuojq6nVAAL8/km3bhrJmzQNs3DiSFi26cP31ivfea/gJNypqKpizdw4zd89kwf4F1PhqiAuLY1T7UfRp1odOCZ3olNCJNo3bEGLS/560C4f+bde0c4jXW4bVugCrdS5W6wL8fisiiuLiPixb9jcyMkZQUDCIESPCGDsW3nmnYR47GAgGqHBV1I3T3Vayje+yv2PFwRUEJECLmBbcddFdjO00lqGpQwk1h575QmraWUQHY007i4kEsds3UFExF6t1HnZ7JiB4vUls2XIN8+aNZuPGETRvHs8118Brr8HgwWD56cfh/mpOr5Nd5bvYUbqDHWU7yKvKO2qSjPKa8rqZqg7rmtiVSZdMYmynsfRp1kd3qtK0I+hgrGlnEZEgTucObLZl2GzLsdmW4fdXAIqqqgGsWPEMs2ePZu/e3gwcaOKGG2DKlNP3yMGgBNlWso0tJVvqAu+Osh0csB2oSxNqDqV1XGuSo5NJS0hjSKshR83pnBSVRGqjVFo3an16Cqlp5wEdjDWtARnBd9sRwXdFbfAFpVqTn381c+deyZw5I3E4Ehg6FP70J7j+emjR4vSUKb8qn0U5i1iUs4jFOYsprykHjE5VnRI6MaDFAO7ueTddk7rSNbEr7Zq00/d3Ne1X0n9BmtYAXK4DFBS8TEnJp/j9lQCEh7chNPQ6duwYyscfD2XNmlQsFhg+HF5+GcaMgcTEU18Wu8fOsgPLWLh/IYtyFpFdYfTCbhrdlNHtRzOi7Qj6tehH+ybtddDVtNNE/2Vp2hnkcGwjP/9FSkqmo5SJxMTfYDaPYunSoXz0USsyMox0Q4fCu+/CjTdCkyanLn8RYa91L+sK1rG+YD3rCtextWQr/qCfiJAIhqYO5YE+DzCi3Qi6JnbV93U17QzRwVjTzgCbbRV5ec9jtc7BZIoiLGwimzc/zMyZKSxeDMGg8ajBF1+Em2+Gli1PfMwT8Qf9FNmL2Fm2sy7wri9YT6XbqInHhMbQr0U//nbx3xjeZjiDWw4mLOQsnftS085zOhhr2mkiEqSiYi55ec9TXb0any+BzMxneeedP5Kfb1R327WDxx+HW281Hkf4c+VU5rD50Gbyq/LJq8ojvzrfWKryKXYUE5QgYMxc1TWpKzd0voGBKQMZkDKAzgmdMZvO7scdatqFQgdjTTuF/H4HNttSDh6cR0XFPEJDD1Ja2prp099g3ry7SUmJZMQIuOwyoym6Vatflk9BdQFPpz/NR1s+qgu44SHhtIxtScu4llzR9oq6n9s3aU/f5n2JDYs9dSeqadoppYOxpv0KIkJNze7aGvA8vN6VmExeamqi2bRpOLt2PUdU1G+48UYLb7wBKSm/Lj+b28YLq17g1fWvEpQgEwdMZEKPCbSKa0V8RLy+x6tp5ygdjDXtZxIJUlW1hpKS6RQXzwEOAnDgQBfWr38Ip3M0PXpcwk03hdKx46nJ0+P38FbmW/xz5T+xuqzc1v02/nn5P0ltlHpqMtA0rUHpYKxpJ8np3EVJyScUF3+Gz3cAjyeCzMyRbNr0OGFhoxk+vBWTJ0Ny8qnLMyhBpm+bzlPpT3HAdoCR7Uby/PDn6dWs16nLRNO0BqeDsab9BI+niNLSGZSUfILDkUUwaGLjxhEsXvwsUVFjue22GP78Z4iO/vV5Vboq2V+5n/3W/eRU5rC/cj/rCtaxo2wHvZr2YsqEKYxoN+LXZ6Rp2llHB2NNO4KI4HLtxWqdT0XFLCorlwJBCgr6MnPmq2RkjGfcuKa8+eYvm4Ky0lXJnoo97KnYQ3ZFNnute+uC7+EhR4clRSXRMb4jn1z/Cbd0vwWTMp2ak9Q07ayjg7F2wfP77dhsS2ufhjQftzsXAJerA/PmPcnMmbcRFpbGQw/BBx9A7El0SnZ4HazKW0VWcRZ7rHvqAvDhqSUBzMpM60atad+kPf2a96Ndk3a0a9yOdk3a0bZxW6JDT0F1W9O0c4IOxtoFyeXKobT0CyorF1BVtQoRPyZTFNXVw1m+/FGmT7+SwsJ2jBwJb78No0eD6Scqph6/h3UF61iau5QluUtYX7gef9APQPOY5nSM78i4TuPoGN+xbmnTuI1+dKCmaYAOxtoFRESw2ZZRUPAqFRWzACEy8iJqav7CvHlXMnXqxdTUhNKhA9x3nzERR4cO9R8rEAyQdSiLJTlLWJK7hFV5q3D5XZiUib7N+/LooEcZ3nY4A1oMICYs5oyep6Zp5x4djLXzXiDgprT0MwoKXsPp3IrJlEBNzZPMn/8A06alYLNBUhLcey9MmAB9+0J9w3VzK3Prnma0NHcpVr7w0z8AACAASURBVJcVgG5J3biv930MbzucS1tfSqPwRmf4DDVNO9fpYKydt5zOIrZvfxuH413M5jJKSrrzxRdTmT37FrzeCKKiYNw4uO0248lIIT/6a6h0VbI0dymLcxazKGcR+yv3A5ASm8KYtDFc0fYKhrcZTnL0KRzLpGnaBUkHY+28Ul7uZsGC+VRWziAt7RvMZj/r1l3LrFkTgWH06qV44w3o3Ru6dYPw8KP39wa8zNkzh6lZU5m/bz4BCRAdGs2w1GFMHDCREe1GkBafpme60n62Ynsxzy5/lktaXcLYTmOJCo1q6CKdEiIBlDLmOLfbN1FTsweAxMRxmEy6T8TJUiLSIBn37dtXNmzY0CB5a+cXp9PL4sULKSr6nFatviMqyo7DEU9p6W1ERPyJHj3ak5Z2bM33SLvKdjE1ayofb/mYspoymkU3446L7uCajtcwoMUALGbLmTsh7bxT5a7i0o8uZWvJVgCiQ6MZ33U871373jl1Yed07qak5H/YbCvx+Urx+cpQKoSLLy4DYPv2Gykv/xqA5OS76dTp/XPq/E43pdRGEelb3zZdM9bOST6fjxUrlpKb+zlNm35LXJyNkJBGlJf/hsTEmxgy5HLMJwigdo+dz3d8ztSsqawrWEeIKYTr0q7j7p53c2X7Kwkx6T+PM0FEqKpaQUzMAMzm8BPvcA6yuqx4/B7m3zaf8JBwpm2dhsvvqgtUUzZOYUirIXRO7NzAJT2W11uGxdIEpcwcOvQB+fmvEBc3iOjoXlgsiYSG/nCbpm3b/2P37meZP/9TJkx4jqiozrRq9WgDlv74RIKos2jsvq4Za+cMEaGwMIuVKz8iOvozYmIqqKmJobh4LKmp47n00hFYLMdvFrO6rGQWZpJZlMn6wvUszV1Kja+GLolduKfXPUzoMYGkqKQzeEYaQHn5LLZvv47w8Lb06DGfyMjjdGH/BUQEuz2TwsK3cDq30bfvRgBycyfjcu3DYmlCSEgTLJYmhIe3JiFhDABebzlmc/RxLw5EBJ+vHI8nD7c7D7f7IB5Pe0pKruHii39IFwgGMCkTSin8QX+9F3jlNeU0e7kZ/qCfvs37clOXmxjTaQwd43/5xOZ+P6SnQ0SEsURGGq/x8RAVHaTKXUXjiMbH3T8QcFNRMYuSkmlYrfPo3n0uTZqMwOstATgqAP/YyJGwdGmQp566mYsvXsawYXsJCYn7xedyOogImzYNwmKJp0ePOfWmqfZUn/InnemasXZO83gOsX37p+Tnf0SjRtuJjw9l//4xNGt2GyNGXElU1LH/MN1+N5sPbWZ9wXoyijLIKMxgn3UfYDzbt1NCJ+7ocQd39byL/i3666a0BhQbO4gmTUZRVbWGjRt7k5b2PklJ43/VMQOBGkpLZ1BY+BYOx0bM5miaNbuvbrvHk0d19Vr8fit+vw2AmJh+dcF469aROBxZmM0xWCyJWCyJNGo0lHbtXgBg7drmeL2Hjspz7drbeeKJa1i0KMjw4QKY+OPcP+IL+HjvuveO29KSEJlAwcMFTN8+nWlbp/HY4sd4bPFjfDz2Y26/6Ha8AS9mZf7JZ0/7fDBlijEW/ve/h+pqIyj+2LPPCktaXk5EMImW677gsstg2DBo1uzwcWzk5PyN0tLPCQSqCA1tQUrKI0REGNPN/VQQNj53Y1Kcv//dxI4dH7F3bwnDh59dgRigqmoldvt6kpNvr3e7zx+kw43TGH1zLh/d9tIZKZMOxtpZKRj0UF4+m+3bPwLmYTIFKC4eQHb224wePZ6RI+u/qj9oO8h/M/7L+1nvY3Mb/2RbxLSgf4v+3NPrHvq36E+fZn2ICz/7/kGcr0pL4eBB6Nev/u2hoQn06DEPtzufnTvHs3PnzQSDbpo2vfNn5yUiKKUoKfmEPXseIDKyKx06vEly8gRCQn6o5XTq9MER+wTw+20Eg+66dS1b/hW3Owevtwyfz1hEfHXbU1IewWQKIyysFeHhrQkPb4Xd3oSOHYOsXXsXCQkWvrOl8O7Gd5l08aQTTmWaHJ3Mnwf+mSvj/kxVsJANzm+5ou0VAHy85WOeWPIE13S8hjFpYxjRbgSRlsjassOsWfDYY5CdDWPHGsE4JgZWrgSXy1jW5GSxMHslo676PSbnCJ765FuiP/fz3nshNG++n/79c2jadAQTJ8ZQVZVOQsK1JCffSePGw+o6Z50Msxm++sr42e2OJCSkDUoJ+fmvkpR0C2FhTU/6WKdTUdE7hIQ0omPHdwDIy3uJQKCK1NTJKGXmd0/tonT2H1EXrT9zhRKRBln69OkjmvZjDsd22bVroixe3ETS05EvvmguEydOkhde2CUlJfXvEwwGZcWBFTLu83FiesYk5mfMctOXN8k3O7+RgqqCM3sCWp2qKpG//10kKkoERD7//Ng0paVfS1HRBxIMBkVEJBDwysGDz4vPVy0iUrf+p3g8h6S4+H+yefMVUlDwtoiI+HzVUlm54qT2/zWmTBH58MMf3mdlidx999OSno78+RPktzPvOukyLFkiYrEYn9Xatca6mhqRZbnL5eavbpbY/4sVJiMJLybIy2telk2bfTJ0qJG+UyeRWbNEfpxVMBiUV9a8IqZnTNLrnV5S6iiVKneVpPw7Tp745iJZvnywpKcj332XIjExAcnKEgkG/b/oswgGRXJyjl1/8OA+WbgwQlavHih+v+sXHfvofILy1Y6v5Pezfy92j73eNDk5IuPHi8yceew2j6dEli2zyJ49E+uOt3v3fZKejmRlDRe3+5D0f/tSSbjjQfEFfL+6vEcCNshxYqIOxlqD8/udUlz8kaxda/xjWLTIIn//+01y443zZepUv7iO8/fr9rnlo6yPpNc7vYTJSOPnG8ukRZMkz5Z3Zk9Aq9fChcZ/mN/8RmTwYJGwMJHVq49Ok5FxkWzY0Lfe/f1+p2zcOFgOHZp+zLZgMCg5OU9LZmZvSU9H0tOReUtjZd2up097ABYRCQREJk0yzu+6644Ognc+tlnu/90jkp6OZO956KTKs327SFycSJcuIi++KOL1Guv/+leRVq1EHnxQZP7CL2TBpsdk5LSRMvbj7rJ8+UTp0WOPvPVWUHz1xAyP3yP3fX+fMBkZ9/k4cXgcIiJSUPBfWZJulvR0ZPnqtnLw4PPicuWLz2ec19atIsOGieT9zD+jlSuNz2PWrKPXZ2eLjB79dW2wu/VXfT/Z5dkyctpIYTLCZGTsjLESCAaOSrN6tUhiolGWN9449hiFhe9KejricOw8av3u3VNl0aJwWbIsUbq9gryZ8eYvLufx/FQw1s3UWoNxOLZSVPQehYXTUKqK/PyOzJnzEkrdwT33JDJ58g8zYXkDXgqrC8mvzie/Kp8dZTuYmjWVUmcpXRK78O417zKhx4S65rvzSTDowWQKa+hinJDfD9OmQVmZ0Wx6xRWwcyc4YjOZuuo7XC8/gVI/fD92exZO5xY6dHiz3uMFAnZA2LXrFmy2ZcTG9sftzqNNm8kopaiqWo7ZHIk1bByPr/mGvY5qhGfolPA5z13+HNd3vv6UndtB20GeWf4Mt3S7hSEtRnDzBBfffR3BhN86+ODdqKP6HIy/5xDPzaogudnvKSp8HUtII9q0eea4xy4qMuY+j4yEefOgVasftg0ebDQ/HzjwP0JMd7Nr9WA67F7OXx57i7zch3nttdfY7Yxh1pYHuK7Xc5hNP4wguPf7e5m1axpvDrmKixNqEO8+CL2IyMjOJDe9jzsXfUrv1MuZMvhvR5UnJgZWrID//AdeeeXkP6MPP4SoKLjsMthWso1CeyFWlxWry0rTUVFM/eAf3HP3/yMnpwvPbM0mNiyWu3reRZ9mfY7ps2G1wquvwl/+AnFH3FH6YscXrCtYx+ujXscb8PLk0ifZcmhL3fO9P/0U7r7b+AzT06Fzbef0GTOM5vq77oJmze4jNnYgUVE/9Fw/cACuvfZuQkN78/wro3j5IhjQZdTJn/wpoHtTa2eUMTXlDAoK3sHpXI/PF8ayZTeyYsX9XHzxEB54APLUCmbunkledR75VfnkV+dT4ihB+OF3VaG4uuPVTBwwkeFthp+3HbACATeZmV1p0uRKWrd+irCw5nXbRIx/OG3aGMsvIRIkELD/ot6uwaAXq3UB8fHX8v33+/jXv+LIzExkyBBYtszoTJRflU/f9/pS6ixlxg2fM77bTdT4aiBgoTD/UYqK3mHw4GIslibHycNHbu5T5Oe/CEBYWGsGDNiLyWSpm2zipTUvsShnEe9f+z5z987ls+2f8eigR7k27Vr2Wffx3e7vGN9tPCmxKfXm4fMZHZ4slmOfyGX32Hl+1fO8su4VRITld6zh0dt6s2oVcMVjcPG/iQqNIi0hjbT4NJ4b/hypjVI5/H910aJH6NnzOpKShh33c9yzB268Ef73P+jV69jtBQWvs2/fRPz+K/jqq28JDY3mpZd85Ofvw+6oIBBwYFIQEIUpJIHwkHACAQf+gBPEC4BSIVgsTTCZIuqO6w14sZgs9f7tlJdDTQ20aGHcB/4xb8CLL+DDH/QbSyCAuzKB6CgT8fFQ4ijB7XcftU9IIJZIU4CICCcuicLurUFEsJgtRJhiEG8UChONGxu/24WFxmtUrIeIyCARlghEhKAE6zqz+YI+LLUXID6fcWETFgaJiUeXu7TUCMbh4UaP8iPnHPB6je0ixrS4oaFBgkEXZvMvn5QlPDyclJQULJajh1f+VG9qHYy1M8LtzqOw8G3y898DKsjP78x3391PScnt3HNPPONu9DE790teWfsKG4s3EhESQWqjVFrGtaRlbO0Sd/Tr+TKD0fE4HNsJC0shN/cJiovfQykLLVr8iVat/kZhUSOuv/0Qm1clM/btR5ky4QksvkTi4uqfV/uwQMAJmDGbwykr+4bdu+8mEKgmJeVh2rT510mN83U6QcTGvn3jqKxcxgsvLOORR0ayYsUf6N37Fa6/3iiDy+diyIdD2Gvdy4IJC+jTrA8Ws4Ur7l3G2hVmvn13FPFNrqDPRd/9ZH5PPQUzZmwhJkYxaVJ3xo83TrDYXkyzGKMbcCAYqLe38ZsZb/LgvAdh7yjSIi/hj/fEMiLleq6+NAW73QjCHo+R9umnYfJkqKyESy8FFVfAvkA6rohsBnZpyYv3XMeQXs345z+heaqD1Isz2F2+m+zybLIrstldvpvVd6+mRWwLADZtgj59jNrdSy+Bw7GN6OjuR3wXxgWLUhAM1v9UsAMH/sGBA38nIeF6unSZXtdCkpubS0xMDPHx8YBgqymgym2l3OOncXgcSRY7JlMYISGNCQlphMkUcdwL1qAEj+lg5nLBjh3QvLmxHFMu24G6x4GGmEIwuRPxlrcgLc2oWdf4aghKkBAVgtlkJsQUglKK4uIgdnsNbdpE4/VX43CU4/UoJGh8d2FhQkJiMxQhVDuqqbTZ8bkjEJOQ0iyKiAgLSoUcdS4iYHVVEBYSRsAVTUzMsZ+liNFi4/Pl4veHEh7egqQk44Jjzx4jfceOYLJ4CAv5da1QIkJFRQV2u502P7pK1kObtAYhIthsy8nOfgOXayYisGrVGObM+RMdOlzGo48q0i6y8d6mF+ky5XUK7YWkxafx7jXvcnuP24mwRJw4k/OU07mTDRu607Hje3Ts+BYtWz7KgQNPk5//b3Jz3+a3962moLAN8de+zOxDb9P1rU/ptrCQKquFv/0NbrgBlPLjdu/H4dhKVdUqqqpW43BspkuXGSQl3UhERHuSksYj4qWg4BWs1gV07jyNmJijq2fbtxs9czMzjaW8PI9p067CYtlDRMTHREVdisdzKyNHvs2AAY+iVHNEhPtn38+m4k18f8v3DEwZWHe8QRclsHNuJAcKkpi8Yy7tcm7nT/3/RP8W/ev9LPr1g+rqi8jIgJtvhm+/Fdrc+jJv7fwHGfdmkJaQdtxhP9c1+yOzNt7BglkxlA79hIfm306YaRJj+lfRpFEIYVEeEhqFERsLA2uL6HZD27awZkcAX+k1YL+ddemwoxsM6WVcHEA0cDmXt7n8uN9h795Gz+aXX4ZRoxYQEjKK9u1fJSVlIiLGNoB33/2px3MGSU6+g7S0qZiOGBrldrtJTU2tDUqKxlGtiItMIaqmgmpPNRGRXQg5iQsrh9fBfut+OjTpQGToD7cQIiKgUSMoKYHk5B9qmYcveppGNyU5KplQcyhmk5k9e0CFQXTtI7iPd7uoaVMTSUnRmM1gtfoIC7MRHqpQ6vBFpMLhiSDHVkicJUDiEYMmgkHjQjAqqgdKhRIM+vD7FftzzHgjqiDMTufEzvVOwakUJCR4cTorcDiakp9vnGN4uNG03ro1iMnNttLttI5rTWJU4gk/u+NRShEfH09ZWdnP20/XjLVTLRBwsm/fJ+Tm/pfw8O1UVTVh7tz7KC//Pdde25px46A8kMNr615jatZUnD4nl7e5nEcGPsLoDqNPOAzkbBcIODlw4FnyPI0p8rckOTqZpKgkkqOSSYhM+Mnxooft3fsQRUXvMmhQAaGhiYgI+yv3889H3ISFTeO7jN/w1AvFTBgQT651L1kF82hc3ondu3NYsmQUBw7cyuOP59GuXWsATKYIYmL6Exd3McnJtxIV1fWo/Coq5pGdfTexsYPo1u2buvU7d0LX2qTx8XD11Zu59darCQ930KPHtzRubAQjlyuHjIw0mjf/HR06vEFQgjy++HFiw2J58tInjzm/55+Hxx+HfjfPZ3ePmxiaOpRZt8wCwFbt4+9PWWjeHCZN+mEfvx+ef16Y/GyAwM2juGNcC6ZeN7Xe8bs+n3HP8ZlnjH/iTz1l1FAP2LPZUrKFm7reBMCA9wfg8DoY12kcl7a+lLc2vMVjgx9jUMtBuHwuwkPC8XgUhYVGcIqPP+FXd5SaGuMpYHa7j+++u5nq6m+IjOzMvn2jeemlqxk16nKee+7ofUQCuFy5REa2r23ulmNmitq1axedO//62br8QT/bSrYRExZD+ybtj9rmdILDYTT5mkxQUVNRd8H849qj32+0MET9jMYqr9f4bn48P3yNr4YSZwkmTDSLTibEBH6/D4/HR1iYH4slAZtNCAnZjt0ey6FDbUhp5aHAt4PwkHDS4uu/OPN4ivB6i4iM7E5NTRgxP3qy6QHbASpcFfRI6nFKpr+t7zv6qZqx7k2tnTJ2e4nMnfukzJvXWNLTkSlTesp9902Vf/+7RgoKRPwBv8zdM1fGTB8jpmdMEvJsiNz+ze2SVZzV0EU/ZYoOfSVr1rSS9HTk7o8Q02Qk+f+o6/35j+X/EBGRYnuxXP6/y+W2r2+Tvy36m7yx/g2ZuWumFFYXit/vkBUr4mTHDqPn6VdbZkvPt/pIkxeayLQZTvn0U6P3rtdrleXLo+p6E6enK0lfkSx3vNhX2nYrF5PJL1OnfixVVRni93tOWHavt1w8nlIpKRH56qtccTr3iojIZ5+J5OYaeRYWTpE1a1LEbt96zP67d98ny5aFirPmQN26+nrO+nxV4vVWyb33Gj1e33q3Rg5UGvvMmFMopvgcAZH7Hqw8ar9gMCgT500UHmkuD8x6QALBgMycKVJdfey5fPzxDz2dc3PrP99gMCj/Xf9fGfbRMDE9YxImI9HPRcsnWz454Wf1c2zeLBIaKjJ2rEfy8l6V+fOvkAULQuXzz/tLoLYjcFnZTKmp2S+BgEe2b/+NrFzZRDye44zlE5GdO3ced9vPVVhdKJmFmeL0Oo+bxuFxyIaiDbKrbNcxvZfPtMpKkcxMkdzcAqmuzhSHw2qsd1VKZmGm7KvYd8zvXTAYFLt9izid2fUe0+PzyIbCDXLQdvCUlbO+7wg9tEk7nTZu3CdTp/5eFiwIlyVLlLzwwvXy3HMrZfNm4w+i2F4s/1rxL0l9NVWYjCS+mCiPL368wcYABwIiTz8t0qOHSN++IpdcIjJ8uDEm9rC//EVk4kSRL74QKS//6eNVuiplasZz8tZs4yJk2bKu8q9/rZQWqU557rnrZNq0TtLz4kL57/r/SmZhprzyishvf2eTlDFTpMn1k8V83e+EW64WJiMfZn0oa9a8L+npyOXPDZbmv7tXaJIt8dc/Kx9lfXTMuEebbY1UVCwQp3OPBAJu2V22Wwa+P1B4Ghn81JOyK69YRIyxsP37i7zySkAydufL4v2L5a2Mt+TP8/4sq/OM8UZ7iwvlkjvnSlikW577v6tl8dIw+Tbjbsm15orbXViX5+ExwD/mch2QZcuj5I5PUiSzMPO4n9fBgy/K8uWR4nCUyNVXG2WrqRF5+GERpYISmXRITL8dJmqykms+u0bm7Z0ngWBA3t/4vjAZmThvogSDQSkoMMbltmkjsny5yKFDIunpRh5+v8jixT/9vR2pzFkm3+z8RortxSe/08/wzjvG79KyZUZgvuIKh1RW7qktq1OWLQuT9HRk5Urjd+jgwX//5PFOZTD2BXyyqWiT7K3Ye8y2YFCkuMQnWTm5suXQFvH6vcds37dPxGY7NWXJzc2Vrl27iojIwoULpXfv3tKtWzfp3bu3LFmypC7PsjKRnJyA2O07xG7Pkn/96x/Srl07ade+nbz+6etS5a466rheb6Vs3TpT+vXrLe3bt5ebbrpJPB7jAnX58uXStUdXMZvN8tmMz07NiYgOxtoZUl4uMmXKRnnllZtk8WKTLFgQKm++ea/Mm7fbGK8YDMjCfQvlhs9vkJBnQ4TJyLCPhsmMbTPEcxK1tNMpGBR5+ul35K23rpd77lkjl19ujIP9y19+SHPRRSKRkUEBI0B0vcgt/3w9XzIKMsTtc4uIyKaiTTL+y/ES+vdYueqZrjJ/iZJpK66RBx7wiMUiMmqUyIsvzpD0dOT557+qO/aYMSLR0cZf3+GlZx+PZBZmSomjRN59d7h88EFXASP/xBZVMn/ByU8+4A/45aXVL0n4P8Ol0fONZHb2bPnqK5GuPdy1+QWE1CXCtfdKxD8jZUrGVJk6VSSxqcfY3ukbSfhrG/n3N0aNe+GK1rJ8eaQUlK2UEsfxa2t2j136vdNFGj/fWPZV7DvOZx+U9eu7yMaNg+q+CxGjpmM2i/zhDyJ2u0h+Vb48teQpSfp3klietUiJo0S8fq98vPnjo2o9q1aJtGsnopTxmTZrJuJp2F+vnzR3rki/fiJW6w/rgsGgOJ17JD//ddm+/UYpLp52wuOcymAs8kPtuMZbc9T6QCAgG7fUSGaWSxyeY2vOVVXGd3eiC9aTdWQw3rRpkxQWGheB27Ztk+bNmx+T3u+vkYyML6R7907icrlk//790qZNG/H7/T9K55Jx466Wzz4zgu0DDzwgb731loiI7M/ZL18s+UKuH3+9fPnll6fmREQHY+00W706KA8/vEhefvkKSU9H5s6NlS++eEyKi40/GmuNVV5c9aK0e62dMBmJfyFe/rLgL5JdXn/z0Jm0fr3I/v0iJSVf1NZgQyQ9Hdm8+cqjan6H/WfVG8I9A4RhTwqt04Wr/iBMRtZn58rllwflnif+I8Nvf1QsES5RKiBr1+aLiEhR0Q81hWDQL+vWdZTMzJ7HNJ35fCIVFSIFBcbyQzlrZP783fLNNyJffSXiPH7r4U/KLs+WSz+8VB6c86CIiHj9Xrnrvefl6ns3SEqqU7r18NROnmHUMAcONCZu8AV8YnPZJN+WJxt3PyXLlkfIrl13yWMLH5Hwf4bLH+f8UXIrc4/KKxgMyo1f3CimZ0yyYN+CuibuH6uqWi/p6Uhh4bvHbKtv9ia3zy2rDq76yfO02/8/e/cdHlWZPXD8+6aQRiAJIZREakJPiHSWIi6ioAiiWBA7KoruIq6KZVUEXCz80HVBcEUEKyoWlEVBEVQQEFBqaAkESCA9gYT05Pz+uCQEMqTghEmG83me+8zMfe/cOXOnnLl33vsekb/9zfqRs2dP1baNIxXZ4SivvZNxQVGBHM85Xv49WlQgOw/Fy6ZN1nv1bLNmvS+dO/eUrl27yv333y+xsbESGhoqycnJUlRUJP3795cVK1bIwYMHpX379nLHHXdIeHi43HDDDXLSxhu7bDIuq7i4WAICAiQ3N7dc29SpT8kLL/xDik8dPr/yyivl119/lcy8TEk5mSLFxcVSXFwsjRo1koJTo6P8+uuvcuWVV5auo7CoUG6/43aHJuMq9aY2xgwF/g24AvNF5KWz2u8CXgXiT82aLSLzq/xPt6rVRGDlymxWrPiQLl3eYMSIneTmNsXL6yX6938AN7eGRKdF87flf+Pdre9ysuAkA1sOZOrlU7m+4/V4ujm2LJ6I1WN14kRrcIUZM76hQYO/0KXLUhIS3iUp6WPc3a2eOQUF6bi7W104B7Xtz6xxBXi5e+Hldggvt37UL25KbtIM/va3/+HnF09sbFdCvV/muutcuPRS6zzWkkH3AYxxpUWLp9i7927S0pbTqNE1pW1ubhBg4/TaXr28gPZ/+nm3a9SOn+76iWIpBsDd1Z13750M91rbJDXV6mXaurXVSzoioqRHqxsNPRvS0LMhIQ2nURz2LC4u9RjXeB+pOcf575b/Mm/zPG4Nv5XJ/SbTOagzM9bOYEnUEl4d8iqdPffz229X07v3Xry82p4RU0LCu7i4eNksBGHrXGkPNw/6tehXvqGM+vXhjTfOdytdeOfuOX2eHnkEtm79U6twA0pOsRbAREYir72Gm4sbnS5pxq4TkJAA/v6nT53buXM3X375CV99tY7QUHcmTJjATz/9xOTJk3nggQfo3bs3nTp14sorryQ2Npa9e/fyzjvv0K9fP+655x7efPNNHnusauUVP//8cy699FI8PMqfdpSQcJw+ffqUdnILCQkhLi4O/zB/svKzyMw5Cjlu+Pn54XbqBOOQkBDi4+MplmIMBlcXV4d3HK00GRtrlPA5wBAgDthkjPlaRKLOWvQTEXm4BmJUDlJUBEuXHmLr1jfp0eNtRoxIJyenK61avUOLFmMxph5rD69l1oZZLN2zFDcXN8ZGCq4/HwAAIABJREFUjOWR3o/QtWlXR4cPWOdLPvigNaDC0KHwzjsQELCQoqIs3Nwa0KLF41xyyWMYYyguzmfz5khSCuoT2Pwf9A29hy6Bobi6WiMs7dv3IEePzgMXb0JDh+LtPZJ+/W7grrsqKQLQZCyxsVNITPz4jGR8toKCDLZuHUTbtq8SEDDEbtvA1peMdarH6dtdK3i5Sk4VadeoHfNHzGfKoCnMWj+Lt7a8RV5RHh/f8DHr49Zza/it/KPvP8jPTyAm5jFiY6fRsePC0vUUF+eRlLSYwMDra11JPWXJK8q3zjsuzCc2dR9t/Nvg7upO06bWKFUnTpweEWvZslXs3r2F66/viYsL5OTkEBQUxJQpU/jss8+YN28eW8v8SLjkkkvod6q+5G233cYbb7xRpWS8a9cuJk+ezMqVK8+5jDGGoqLcUwU9BBcXF9o3ak9qTipuhbEcSU2goLiA3MLc0p0DYwxJJ5NIzU6lQ2CH899odlKVPeNeQLSIHAAwxiwGRgJnJ2PlJPLyhC+++Jljx96ga9evGDQIsrOvp3PnvxMY2J/C4kI+2bWEWRtmsfnoZhp5NeKZAc8woeeE0kEYzpeIdW5jgwbW8IC7d1tD3CUkWNOxY3D0WDFPzPmJ9l1yOHk4jLjtYXTrBl27Cn5+pwcDiI+H4cNh2zaYPj2Za6+9Fx+fNzCm5RkVfEoGEBApxjS4juKjb5AXN47NGf/h5MnddO++kfr1u9Ks2X0EBAzD338Irq5VPwfaxcWdyMjVeHq2rHC5xMT3OHlyW+leem0V0iCEWVfN4pkBz5BdkI2LceGrm7+ioLgAYwweHs1o3vwh4uJeo2XLp/H2turyurh4cOmla7EOsCm7ef11u60q5UQ8x7KO4WpcqVdcWPpDLiDAGgyl7LghLi7CDTfcydy5M86Yn52dTVxcHABZWVn4njqH6OxBR4wxbNy4kfHjxwMwdepUIiIizlgmLi6OUaNG8d5779G2rXWU5csvv+SFF6zhRefPn09ISAhHjhyhqCiTgoJEjhw5SPPmzTHG0NDdhdwiCGraluMZxzmRcwJPX0/i4uJo1rwZiVmJeLl7Vel0w5pWlWQcDBwpczsO6G1juRuMMQOBfcAkETliYxlVixUVFfP555+Qm/sSLVpsp0GDAHJzH2fQoAnU82zGz4d+5pstk1gStaT0fMN518zj9q63n/eY0AkJ8MEHVtItmTIyYOlSGDHC+jU+Y4Y18IB7gxSyPKJJb7qbR398CbbvI3TPXKIXlxSjN7gGHsCnxT663D2HcT3H4ud3C8uWZdOkybVkZGwnPz/h3EnRuDNx/QYSTgSyYuQETmasIDh4Aq6u1peJr283fH27ndfz9PKyjsEWFWXj6lp+W4kIR4/Ow9e313k/xoXWyLsRjbB+OLi6nFlvt0WLJzh6dC6xsS/QqdOHpfPPPr9Z1S5N6jch6WQSxhhCA0JLX1MXFwgLO3PZ4cMHM3LkSJKTJxEUFERaWhqZmZnMnDmTsWPH0rJlS+677z6WLVsGwOHDh1m/fj19+/bl448/pn///vTu3fuMvefY2NjS6xkZGVxzzTXMmDGjdI8aYNSoUYwadXrccS8vL2699VYmTZrEkSPHiY7eT/fuVlIvKEjGmHoE1W/N4L8OZtWyVYwZM4Z58+fR74p+FBQX0Lr+eY4la2/n+jO5ZAJuxPqfuOT27cB/zlqmEeBx6voDwI/nWNf9wGZgc4sWLez2R7n68/74Y6V8+OGlsno18vHHnWXFircl8fhheX/b+3LTZzeVlm/zmOYh13x4jSzbu+y8zjfcv1/kuutE3nnHuh0VJdKgQYpcc82X8swzM2TBgrtk2bK+8ssvobJu3zx5cfXLkpkZI4mJn8kjX18jPeZ1lGdWPSNrD62V9UfWy5ajWyQhQeTbb0WuuPdHaf2XzeIbfFg6/LuLmClGvti1RHbsGCWrVxtJSvqywthmb5wtTEE+3P7h+WzCSmVkrJdffvGX9PRfyrWlp6+R1auRo0cX1MhjO0J09GRZu7axFBRkSE7OEdm1a8w5z/NU1WPvDlxlZeVlSU6B7VJpJZ0Os7Ks64sXL5auXbtKeHi4dOvWTdasWSO9e/cu7c08atQoWbBggRw8eFA6duwo48ePl/DwcLn++usr7cA1bdo08fb2lq5du5ZOieeoozp9+nRp06aNtGsXJkuW/EeysnZLYWG2DBnyFzlw4HcREYmJiZGePXtK27ZtZdiIYbLuwDqJSoqSjRs3SnBwsHh7e0tAQIB06tTJHpux2h24Kh2ByxjTF5giIleduv3UqSQ+4xzLuwJpIlLhn0I6AlftkJKyhZ9+mkyjRqtISmpJVt5TJLfM4H8x/2PdkXUUSzFNfJowvN1wrm13LVe0ueK8xoQ+eRL+9S94883jXHPNO9x22ypCw28ntTiUhvlJJByx/kvNLvYiKd+DY9m5zInOJSHXlT9unUpq3OlRnNzcGuHlFUqHDgvx8bH9X09OQQ4Tv5vIhLbFZCS9UzoM4bkcyzxGhzkd6BXci5W3rayRwhNFRSfZsKEVvr49iIj49oy2qKgxpKV9R9++8Tb3nOuiwsLjgMHNrQGHDv2LgwefoXfv6HKdulT12WsEruo6etSaXF2tjnNn7y2fS2xsLMOHD2fnzp01GyBQUJBKbu5BXF0bUlycjbd3J1xcyo+odTL/JO6u7tRzLT98pj1UdwSuqhym3gSEGWNaY/WWvgW49awHaCYix07dHAHsrm7g6sLKzo5m/fp/4ur6CW5ujfh53QyiW8SzOPZvFBwooGuTrjzd/2mubX8tPZr3KP3vqLjYGiKxdWtrbNeq+OYbePbZQ/Tr928Wf/I2HvWyiD0J//pqOb+kwI+3/Y/u3Tbxw+HdPPL9MwQ3CKaNfxteGjqMq8OupmE9D7KbXE1ubgw5OQfIyYkhJ2c/np5WrbkjR14jM3MTjRoNJyBgKO7uAXi5e/HmsFn88Ud/mgf/nRyvqyuMsZF3I57q/xSjO42usQpQrq4+hIQ8ysGDT3PixGYaNDj9mWzc+Gb8/AY5TSIGSjtpiRQRF/caDRsO0ERcxwUFWX8tFRVVf2jQC8XNLQAPDzl1VoTLOT/Pta3QTJXGpjbGXA28jtXzYoGIvGiMmYq1y/21MWYGVhIuBNKAB0VkT0Xr1D1jx8jPTyQqahqpqW+Rn1+P73/4O7v9XVhZ/BLuLu6Mu3Qcj/Z9lLYB5b80jx+HO+6Ar7+2xpMdOBDmzau8fN+HHxbh49OShg0T+SGpkB9TGzEwbBwt/VoS7BtMvxb9CPQOrHglFYiNnU58/BsUFCQDLjRs+BcaNx5NSMhECguzeOyHp3l/+4f8cvcvdGrcqdz9ReSClWAsLDzBhg0t8fO7/IwxoJ2ViPDTT9YPufbtF9Cs2d0Ojsg5OGrPGKyOkSkpEB5eA6dpOZHq7hlroYiLREFBGjExrxIf/waQx7ff3stPSV3Y3PIf+Hp78GCPB5nUdxJN6ze1ef+sLKsKzcGD8MwzVmJevdqq5uPrC7Nnw8aNMGQI9OpVxFdffUOHDh8T2vdpfj3yG9e3akP9+u35JmY917S75rw7fJ2LSBGZmZtJTV1Gaur/8PAIJjzcKjxwIP0A/Rb0w9W4su6edbT0O92BK7sgmyvfv5JnBz7LVaFX2TWmczl48HkOHZpK797ReHq2Ii7udYKCbsXD48/1RK+tYmOnERf3On36HMLNrb6jw3EKjkzGJePGaSKumCZjdYbCwuPs2PE6KSmzcHXNZPXqW/hi7Q1EhT9Jo5B0HunzCA/1fAh/L/9K1/XiizBgwFK8vJ47VRe3mPbt38bffzCzZ39Ps2Z3U1wseHjk0KBBOqkngpi4O4lc04jYR2KpX+/CfREXF+efUUpte+J2Llt4GUE+Qfxy9y8E+QQB8OQPT/Lyupf56a6fGNhy4AWJraAgjezsvTRs2JfU1G/ZsePqU2UNyw+E4QysDiqFNv+3U+fHkclYVU1N/Ges6qDCwpOsXfsfcnJexcsrjQ0bRrF0y9Vsafw2wddO5LW/PMZ93e6r8H+TggJ4+mkYPdra2x0z5lkOH54BdKFBgz4YY3Bzs5L4nXc2Jj5+KPGJuWzed4wVOw/ymxzjoV5P8ES/Jy5oIgbK1TSNaBLBsjHLGPL+EEZ/Opqf7vqJnUk7+b/1/8fdkXdfsEQM4O4eQMOGfQE4enQu7u5NCAwcVcm96i5jDMZoIlaqIpqMnUx2di7Ll8/Dw2MGvr5J7Ioaxrf7BvBj/dk06f8r/xn4T+7rdl+5eqRnS0yEm26Cn3+2DkP36gWZmVto1ux+QkP/jWuZwuUigtRrQ4cO8/FqeoiR6zpzV+RdfDjgmT89CIg99WvRjy9u/gI/Tz8EYfyy8fh5+vHqkFcdEs/OnTeQmvoNLVo8bbMgulLq4qFH/Z1EQYHwwQef8u23oQQGTiIuvjNzVj3B4+mr+b3NK/zruoeJ+XsMD/d6mGlTPHjlFWtkqzVrYP9+a9jIEuvXW/8Pb9oEixf/xuTJRzHGlfDwr2nf/q3SRFxQVMBHOz6i59s9uekzq1h7S7+WJDyWwOyrZ9eqRFxiaOhQ+oT0YXfybo5mHmXmkJk08nZMt1AXF2s7Nm9+v0MeX6naJjY2li5dugDw/fff0717d8LDw+nevTs//vjjOe83Y8YMQkNDad++PStWrLC5zMGDB+nduzdhYWHcfPPN5OfnA/Dzzz/TrVs33NzcWLJkif2fVBVpMq7jROC77/Yxf/6VhITcTG5eYz7Z+QAPJ/7Mcq/Z/C38eR6VePJWPYVPPR+Ki+HNN2HyZLjtNrj8cmjXDkqGiM3Jgf79wdNTWLNmHk2b9icmxmp0cbH2po/nHmfmrzNp+0Zbxn4xlqz8LK7veH3JwC4X/JD0+XB1cWVUh1Hc0fUOh8XQocMCevbcVekwmUpdjAIDA/nmm2/YsWMHixYt4vbbb7e5XFRUFIsXL2bXrl189913TJgwgaKionLLTZ48mUmTJrF//378/f155513AGjRogULFy7k1ltvLXefC0mTcR22fXs2//rXs7i4hNOy5SZ+3Hcr98ZE8U7ipwzOXEiPH9KYPeZJnnvKm59/Pt0DMjExnePHi9i9G374wSqiMHastc6cHLjvvmy++OIusrMfxN//CsLCZpN0Moms/CwA5m2ex+PfP05oQCjfjPmGqIeiuL/7/Rfs9CB76BDYgdeGvubQmF1cPPDxKX+qlVJ1xQcffECvXr2IjIxk/PjxHDp0iLCwMFJSUiguLmbAgAGsXLmS2NhYOnTowJ133klERASjR48mOzu7wnVfeumlNG/eHIDOnTuTm5tLXl5eueWWLl3KLbfcgoeHB61btyY0NJTffvvtjGVEhB9//JHRo0cDcOedd/LVV18B0KpVKyIiInBxcPdw/c+4DkpMhHnzltGu3d/o1y+WnYcG89KxzRzLX8wdXe/AY9XrvPWfhrRuDf/8p7UHHBqaB9QDDJs2dSE/PwF390AaNGhCYGATAgKuAR7Bz6+Ae+8dSHr673gGPsDXqc0Y/941bIzbyKLrFnF719u5v/v9DGk7hG7N6sYYyko5vUGDys+76SaYMAGys+FqG4Pe3HWXNaWkWL00y1qzptKH3L17N5988gnr1q3D3d1xJRTj4+Pp06dP6e2S8ohlpaam2iyhWJtoMq5DcnNh7txY8vMnctllX5OU1oZ//hHMuhOrGOT6FP8ZcC+jLm/DwQi47eZiGrXbx7bDn7Ph8Ptsjz3E+6mDWTpmGS1bPsvr6/6JFCYR5JVBY49o4mNjcD+UxxP9HiM39xCvxgSw/Kd5APRs3pMpg6bQJ8R6w/t7+VfpVCillPNatWoVW7ZsoWfPnoDjSijaOj337CNeVVnG0TQZ1xHffpvOjz/OZPDg1zAu8MHe1ixMPMDlrYbwj6xf+fcLLZCBeYy6HFq1Emb+3o9WiRvoGQDZBv7ICaZHM6uSSXDwA3Rp50VsRiwHsxJYn5lAQlYCf/FMAlz4y1/iCM18ggXdIhkWNuycA4EopWqJivZkvb0rbg8MrNKe8NlEhDvvvJMZM84sU+CoEopl71NyePv0UwwkIyODwsJC3NzcbC7jcOeqIFHTU/fu3c+zFsbF5cCB4/Kvf02Vb75pKKtXIy8uaiWNZyC93+4t/9vxk4y+sUBAxL/rz1L/n4GSfDJZUlO/l9Wrke/XNJCNuyZKbl6Ko5+GUsqOarJqU1Xt2rVLQkNDSysppaamSmxsrDz88MPy4osvygcffCDXXHONiFjVmAD59ddfRUTk3nvvlZkzZ5ZbZ9mqTenp6RIRESFLliypMI6dO3dKRESE5ObmyoEDB6R169alVaPKGj16tHz88cciIjJ+/HiZM2fOGe133nmnfPbZZ9XcCudW3apNmoxrqZMns+Tdd1+WpUsDZPVqZOb8rtLmJTfpPKezLN2zVH7d+o3cdPsrMnHig/LGe8Gy/AcXWfxTX8nIyZDi4iJJSPhACgttl0FTStVttSEZi9TGEortZPny5aXzhw0bJvHx8SJyZgnF0aNHS25uroiI/Pbbb3WjhGJN0eEwbSsqymXNmrfIyppBw4aJbNvbh7kJB8BPeKr3LQxsP4nW/q35eW1ziguPkVfogYdPGM0bDSAgYBiBgdc6+ikopWpYXRsO80KWUKwtdDjMOkqkmN27F3HgwLPUrx/P4bh+vLO2LfnNt/DsgHY0c4kiK3MOw8f3Zs2c1nQN/5wCfGjUoAvG6BlqSilVl2kyrgWysnbxyy8P4OW1liNHevHeH1eR1vYDnrsygGD3PHKLdvD13iYsf/tD9m8ZzJdXwP3393V02EopVSWtWrW6qPaKz4cmYwcqKspm+/ZppKXNJD/fl/e/+Tvf+nxFjwENmN3/bVIO/Y239tVj67L57F12G8HBhm++geHDHR25Ukope9JkfAFlZKxFJA9//8GkpCxn+/bRuLjkUFjoSX3fDO6/6Q0uywvjktaT6N76alKDruK/7wp7lzXl4YetEoanzhJQSinlRDQZXwAiwqFDLxIb+yz+/kPYt28eOTlLyM314eCxjhx2j6ehXzBR6Qn8nrqfAWkb6eB2NW3aNOHNV+DxB6HMADNKKaWcjCbjGlZcXMj+/Q9y7Nh8fH17kZLyK4WFRbz/0fN8cvwQl14TRVyyD8cOxjC49RVcX/wWcya0IbobrFoFTZpYk1JKKeel3XBrUFFRDjt3juTYsfl4efUhM/M3tmzpz90vzGZd21Usm3kL93W7l2amKxMK95Iy63tefLwNERFWZSWllLqYOKKEYl5eHjfffDOhoaH07t2b2NjYStd7zz33EBQUVBqrPWgyrkEuLh64utbHw2MAOTkb+OLLB/nnhhDk+md5aNCNXBZyFeO6jePuest5c3o73Nzg3Xdh9Wpo397R0SullONcqBKK77zzDv7+/kRHRzNp0iQmT55c6XrvuusuvvvuO7s+X03GNeDkyd3k5h5GpIiMDENe3i+8//E/eDs7hoLArWR//RJTR47n/ffBxbhw222GnTth82ariIqDK3kppVSVOEMJxaVLl3LnnXcCMHr0aFatWoWIVLjegQMHEhAQ8Oc23ln0P2M7y8j4hZ07R1K/fiTp6d4Y8z/eevdpvknxIHfLK5DYlTwP4brrDCVHOPz8rEkpparrke8eYWvC1soXrIbIppG8PvT1CpdxlhKK8fHxXHLJJQC4ubnRsGFDUlNTq7Ree9J9MDtKSvqMbduuwN09kITELESW89p/n6OoXwHZ24bRzKcF8+ZBQoJh8WLoq+N2KKXqqLIlFCMjI1m1ahUHDhzg3nvvJTMzk3nz5jFz5szS5c8uobh27doqPU5JCcW33nrLZrutIZ2rU0LxXG1VWa896Z6xnSQkvM+ePXfg69ubuKM51Pf+nRmvvM3Qhxrzj2tHsGVQPJeG+ushaKWUXVW2B1tTxElKKJbcPyQkhMLCQo4fP05AQECV1mtPmhrsoLi4kLi416hfvz979x/Hy2MPzz+/hJ2xV5BfUAxA93bBmoiVUk5j8ODBLFmyhKSkJADS0tI4dOgQkydPZuzYsUydOpX77ruvdPnDhw+zfv16AD7++GP69+9P79692bp1K1u3bmXEiBFnrD8jI4NrrrmGGTNmlO5RA4waNar0Pj169GDEiBEsXryYvLw8Dh48yP79++nVq9cZ6zLGcPnll7NkyRIAFi1axMiRIwEYMWIEixYtAmDJkiX89a9/xRhTpfXak6YHO3BxcaNRowXs2XMM/4aHeXb6B3S7xZWEW1qzqeA9m4c7lFKqLuvUqRPTp0/nyiuvJCIigiFDhhAbG8umTZtKE3K9evV49913AejYsSOLFi0iIiKCtLQ0HnzwwQrXP3v2bKKjo5k2bRqRkZFERkaWJv6yOnfuzE033USnTp0YOnQoc+bMwdXVFYCrr76ao0ePAvDyyy8za9YsQkNDSU1NZdy4cQCMGzeO1NRUQkNDmTVrFi+99FKl6x0zZgx9+/Zl7969hISElPbM/jO0hOKfkJ29n717XyEk5EY2broZKYLXPpnKY8+FMurT6+jZvCff3/49Xu5ejg5VKeVEtIRi7aclFC+Q5OQEfvvtKlxckklLe5fU5DA+2vgwr83sz2ULL6Otf1u+HvO1JmKllFKV0mRcTSLw0UcnKCgYSkjIEdzcCtmwYRhf7xnD2nfH8u8N/6Z+vfp8d9t3BHjZ9zw0pZSqi7SEYuX0P+NqEIHhw/NISRlOy5bbcXMrZPHix3jrt1Hc9EAqLsaFSX0nsePBHbRo2MLR4SqllKojNBlXUfLJZIyB665bQXjEWoqKDS+9tJC39noR2/V+Jq2YRGZeJgD+Xv4OjlYppVRdooepq2DS9D28Ff1PPvx7Wzp0mEva8YY89cS3pLfdyhevXUob/6209GuJr4cWG1ZKKVV9mowrMWH6Fv47JYJXZsfif+JzDiV2ZNLDK2k86FeOfHIvbi66CZVSSv05epi6AvdO+5kl/wlk/qKOdOuwhYwTTbnvrt8IvGwd2xaP0kSslFJ2pCUUVTkvvxXLruUZLFgQTqvgA5zM8eeO23bR4uplbPtkFO6u7o4OUSmlnJaWUFQApETXY+rUm2jgKxQVuzFp4g/4913DtsWjqOdaz9HhKaWUw2kJRfvR46xlFBUX8fjyv3Fz5J288kpvdu4cTWrqh8x6bS5xJo/Dn/8VT/fyJbyUUsqRBi0cVG7eTZ1vYkLPCWQXZHP1h1eXa78r8i7uiryLlOwURn86+oy2NXetqfQxtYSifWkyPiW/KJ8Jb4zj2tBl/LK5gLaeSaSmfsi339/Kd+uGsW5DAYH1teiwUkrBmSUUAXJycggKCmLKlCl89tlnzJs3j61bT9dZPruE4htvvFGlZFxSQnHlypU227WEohMplmKmLryC2y79hdjDXbhp0C3s3n0DMYc68drr/2HOJ3vp006LDyulaqeK9mS93b0rbA/0DqzSnvDZtISifel/xsCsLydwRdtf+OXXmxh65U8kJv6DzJPF/PPJZYx9+jceGK6JWCmlytISinYmIpVOwFBgLxANPFnBcqMBAXpUts7u3btLbZCWlijfLGsg897qJgcO5EhU1B3y449GevVaLl1v+FaKi4sdHaJSSp0hKirK0SGIiMjixYula9euEh4eLt26dZM1a9ZI7969pbCwUERERo0aJQsWLJCDBw9Kx44dZfz48RIeHi7XX3+9nDx5stz6Dh48KJ07dxYRkWnTpom3t7d07dq1dEpMTLQZx/Tp06VNmzbSrl07Wb58een8YcOGSXx8vIiIxMTESM+ePaVt27YyevRoyc3NFRGRnJwcGT16tLRt21Z69uwpMTExla73lltukaZNm4qbm5sEBwfL/Pnzy8Vk6zUCNss5cmKlJRSNMa7APmAIEAdsAsaISNRZy/kC/wPqAQ+LSIX1EWtLCcXUVHjxxfe44qpedO2yhv37H2The//k603XEr8lEq962nNaKVW7aAnF2q+6JRSrcpi6FxAtIgdEJB9YDIy0sdw04BUgt3ohO4aI8Oz3E8kwMfzf/91B/74n2L9/Ir9tuZyPlt3Nb9+11USslFLqgqhKMg4GjpS5HXdqXiljzKXAJSKyzI6x1ah/ffgUfyl+i+Wb3kIkj527xpCYEsiLMxbw2ZJiQoMbOTpEpZRyClpCsXJVSca2+nKXHts2xrgArwH/qHRFxtxvjNlsjNmcnJxc9Sjt7NstK+ns+zYJiW24tccU4uPnkJ93gP97ZQEPv5DCyIGhDotNKaXUxacqyTgOuKTM7RDgaJnbvkAXYI0xJhboA3xtjCl3XFxE/isiPUSkR+PGjc8/6j8h6UQq+zY9hYdHLqHtF+Lrm82+6Cls2DAM19Y+vPiQzcP5SimlVI2pSjLeBIQZY1obY+oBtwBflzSKyHERCRSRViLSCtgAjKisA5ejvDb3Mbp2+J1Dyc8xoHcvYmNfgOJs/vv+k3z55qWODk8ppdRFqNJkLCKFwMPACmA38KmI7DLGTDXGjKj43rXLiRNQnN6IqP3XM/62Jzh5cg9x8XNZtux+BtwgNG3k4+gQlVJKXYSqNOiHiCwXkXYi0lZEXjw17zkR+drGsoNq415xdFo0Lp5ZPDl5JuPu+AxjDPv2PUZOtjcfrxzDf5/tV/lKlFJK1ZjzKaGYmprK5ZdfTv369Xn44YfP63EXLVpEWFgYYWFhpQOAgDU4SXh4OBEREQwdOpSUlJTzWn9VXBTDYaZn5rDgvTs5HFjEB7dtAFxIT1/F8eP/44MPXuaRp9zwcL8oNoVSStUJJSUUmzdvzs6dO7nqqqtsFmrw9PRk2rRp7Ny587x6bKelpfHCCy+wefNmjDF0796dESNG4Ovry8SJE4mKiiIwMJAnnniC2bNnM2XKFDs8u/IuiuEwZy54kysjf2Wwz18AECliV9QjHEtoyU8HL2WgGjbUAAAgAElEQVTy2D6VrEEppdTZakMJRR8fH/r374+np2e5tpUrV9K3b1+6devGjTfeSFZWVrllVqxYwZAhQwgICMDf358hQ4bw3XfflY6MdfLkSUSEEydO1OjY1E6/O1hUXIwfX5GW3pjbr/0XAAkJCyks2Ml/3/6AubOa1mglDqWUqkmPPAJliiPZRWQkvP56xcvUlhKK55KSksL06dP54Ycf8PHx4eWXX2bWrFk899xzZyxXtoQinC6V6O7uzty5cwkPD8fHx4ewsDDmzJlT5cevLqffM577xWJ6dl3LobRRuLl5UliYyZ69T7Nz519I9G3AyL+EOzpEpZSqc8qWUIyMjGTVqlUcOHCAe++9l8zMTObNm8fMmTNLlz+7hOLatWur9DglJRTfeuutasW3YcMGoqKi6NevH5GRkSxatIhDhw6VW87WkNDGGAoKCpg7dy5//PEHR48eJSIiolyFKnty+j3jtNgl5Dfw4Pbrngfg8OFXMCTx5oKFLP6yk4OjU0qpP6eyPdiaIrWkhGKPHrbHhhARhgwZwscff3zG/LMfMyQkhDVr1pzxmIMGDSqtxVzyuDfddBMvvfRSFbbM+XHqZFxcDLlpQ9kX3ZErr2xObu4RYmNf5ccfbyV4wEkiWrZ0dIhKKVUnDR48mJEjRzJp0iSCgoJIS0sjMzOTmTNnMnbsWFq2bMl9993HsmXWKMklJRT79u1broRiidjY2NLrFZVQHDVqVKXx9enTh4ceeojo6GhCQ0NLfySc/ZhpaWk8/fTTpKenA9b/zDNmzCA3N5eoqCiSk5Np3Lgx33//fc0W5zhXOaeani5ECcXs/GwRESkqsm7v2HGbfLfCU5p2+l6STqTV+OMrpVRN0BKKZ2rZsqX4+/uLj4+PBAcHy65du0REZNWqVdKjRw8JDw+X8PBwWbp0qc37v/POO9K2bVtp27atLFiwoHT+3LlzpUOHDhIeHi7Dhw+XlJSUKm8bu5dQrCk1XUJxf+IBnvh0AGP/+gqjO4/lxIlN/P57Lz744Glcu1zKW4+MrrHHVkqpmqQlFGu/6pZQdNrD1G999BoTLz1KbmoxIsLu3Y+Snt6YL//ow9F5Vzo6PKWUUqqUU/amPp5zgrCGP3IkPpQr+48lJ2cfOTlr+fCjJ3n6eYOHW9W7xyullPpztIRi5ZwyGf97yWu0bxNFRu6duLi4cOiIdTj8sHsek6692sHRKaWUUmdyumRcLMW4pq3gRKY/d4x+FIAde9dSWOjGsCFdcTFO95SVUkrVcU6XmTJPFBFQT4g5fBsNG3oDkJO9g0OHOnL1wDYOjk4ppZQqz+k6cDVs6M611/6Kq2vh6Xne+/htTz9ub6XJWCmlVO3jVHvGa2NXMfazEbg0PEazZu4A5Oen4NcgmbiMIOq51nNwhEoppc7lYi6h6FTJeMlXs7m9wUpy009X5khN3QZAlktjR4WllFKqmkpKKO7YsYNFixZx++2321yupIRi2XGwq6OkhOLGjRv57bffeOGFF0hPT6ewsJCJEyeyevVqtm/fTkREBLNnz/4zT6lCTpOM96XspVfz3zh4qCutL2lXOn/v/k0ANAi65Fx3VUopdR60hKL9OE0ynr/0XzQPOoqL20OUHY/8aOImUlKa0at7iOOCU0qpGjRoUPnpzTettuxs2+0LF1rtKSnl26qibAnFrVu34urqekYJxf/7v/8rLaEIsHfvXu6//362b99OgwYNeLMkwCr4syUUf//9d3r06MGsWbPKLVeVEorNmzcnKiqKcePGVfnxq8spknFaThrBsomExBaMGX3rGW2uZhfRBztzWdfWDopOKaWcj5ZQtC+n6E0dfziWrqG72fj7VBo0OP2UiovzaeR3gB+SuhPWKNSBESqlVM0pUwGwHG/vitsDAytuPxfREop25RTJuFXzbvyyKorrrw0+Y35mZhRubgUk5vppT2qllLIjLaFoX06RjH19YcKE8hvpwAGrJ3WRT8CFDkkppZxap06dmD59OldeeSXFxcW4u7sza9YsNm3axLp163B1deXzzz/n3Xff5fLLL6djx44sWrSI8ePHExYWxoMPPljh+mfPnk10dDTTpk1j2rRpgJUog4KCyi3bqlUrTpw4QX5+Pl999RUrV66kU6dOLFy4kDFjxpR2/Jo+fTrt2rU7474BAQE8++yz9OzZE4DnnnuOgAArZzz//PMMHDgQd3d3WrZsycKSP9prgNOWUAT4ZtlE3N3e5qsjM5l334QafSyllLpQtIRi7aclFMvIyv6djLTODOzdxNGhKKWUUufkFL2pbRERGtTfSUz8JXQN7uDocJRS6qKlJRQr57TJOC8vHh/vDGLSfQlrFObocJRSSqlzctpkHB9vdd5KFW/tSa2UUqpWc9pkHBtrJWPPJn4OjkQppZSqmNN24ErP+J38vNZEdtVkrJRSqnZz2j1jF5etRB9qR49QHQZTKaXqAkeVUBw6dCh+fn4MHz78jPljx46lffv2dOnShXvuuYeCgoLzWn9VOGUyLio6iV/DA8SkBNC5cWdHh6OUUqqaLlQJRYDHH3+c999/v9z8sWPHsmfPHnbs2EFOTg7z588/78eojFMm47S0nbi4CAdOGu1JrZRSNcQZSiiCNbRnyRjaZV199dUYYzDG0KtXr9Ixt2uCU/5nHB1tjTua5eGuPamVUk5t//5HyMraWvmC1VC/fiRhYa9XuEzZEoru7u5MmDDhjBKKvXv3Li2hGBsby969e3nnnXfo168f99xzD2+++SaPPfZYleL5syUUfXx8ePnll5k1axbPPfdclddRoqCggPfff59///vf1b5vVTllMk5K2oarawOahvo4OhSllHJKZUsoAuTk5BAUFMSUKVP47LPPmDdv3hkFGc4uofjGG29UKRmXlFBcuXJlteIrW0IRID8/n759+1ZrHSUmTJjAwIEDGTBgwHndvyqcMhkXFGwl9nAXenZq7OhQlFKqRlW2B1tTnKWE4ogRIyp8ni+88ALJycnVrqdcXU6XjEWK8fXdTswfV9H/r50cHY5SSjklZymhWJH58+ezYsUKVq1ahYtLzXaxcroOXNnZB/DwOEnMcQ/tSa2UUjWkbAnFiIgIhgwZQmxsLJs2bWLy5MmMHTuWevXq8e677wKUllCMiIggLS2tWiUUIyMjiYyMJCkpyeayrVq14tFHH2XhwoWEhIQQFRVF48aNS0soRkRE0KdPH/bs2WPz/gMGDODGG29k1apVhISEsGLFCgAeeOABEhMT6du3L5GRkUydOvVPbLGKOV0JxZ07PyclZTQPfjSKbXMXawcupZTT0RKKtV91Syg63Z7xkSPbKCpyoSjAaCJWSilVJzjdf8ZZWVs5ebI9XcLLn3OmlFLqwtMSipWr0p6xMWaoMWavMSbaGPOkjfYHjDE7jDFbjTFrjTEO6zlVz2MbMfGtCG8e6qgQlFJKqWqpNBkbY1yBOcAwoBMwxkay/UhEwkUkEngFmGX3SKugoCCdhg0OE53agM5B2nlLKaVU3VCVPeNeQLSIHBCRfGAxMLLsAiJyosxNH8AhvcKOHdsOQMzJIjo11tOalFJK1Q1V+c84GDhS5nYc0PvshYwxDwGPAvWAv9olumqKidmKMXDQpNCuUTtHhKCUUkpVW1X2jI2NeeX2fEVkjoi0BSYD/7S5ImPuN8ZsNsZsTk5Orl6kVZCWto309Mb4tyzQntRKKVXHaAnFisUBl5S5HQIcrWD5xcB1thpE5L8i0kNEejRubP+hKkW2ERPbiYi2Te2+bqWUUheOllAsbxMQZoxpbYypB9wCfF12AWNM2TqF1wD77Rdi1RQXF9Cw4S6ikwJ15C2llLoAtISi/VT6n7GIFBpjHgZWAK7AAhHZZYyZCmwWka+Bh40xVwAFQDpwZ41FfA7Hj+/F3T2PmEwX/qo9qZVSF5E//hhUbl5Q0E0EB0+gqCib7duvLtfetOldNGt2F/n5KezaNfqMtksvXVPpY2oJRfuq0qAfIrIcWH7WvOfKXJ9o57iqbf/+bQDEFBzXntRKKVXDtISifTnNCFzHjm3Dy6secR5HtCe1UuqiUtGerKurd4Xt9eoFVmlP+GxaQtG+nCYZ5+VtIympE23C8rUntVJK1TAtoWhfTlMowtt7KwcTWtClSd2pZKKUUnWVllC0L6cooZiXl8D69c2YvfRGOo/oyAuXv2CX9SqlVG2kJRRrv4uyhOLBg1bnrejcXO28pZRSqs5xiv+MDx5MpqioATHmmBaIUEqpWkZLKFbOKfaMCwtv475/7CLbfx9hAWGV30Eppeo4R/3FqCp3Pq+NU+wZX3st9Mn+G3tSmuPhVvWTwpVSqi7y9PQkNTWVRo0alTtlSDmWiJCammpzRLCKOEUyBtiVtIuIJhGVL6iUUnVcSEgIcXFx1ETBHfXneXp6EhISUq37OEUyzi3MJSY9hlu63OLoUJRSqsa5u7vTunVrR4eh7Mgp/jPem7KXYinWAhFKKaXqJKdIxruSdwFoT2qllFJ1klMk47CAMCb2nqg9qZVSStVJTvGfcc+iJvSM6wJZOeCnvamVUkrVLU6xZ8y2bXDffbBvn6MjUUopparNOZJxcLB1GR/v2DiUUkqp86DJWCmllHIw50jGjRuDu7smY6WUUnWScyRjFxdo1kyTsVJKqTrJKXpTA7BypbWHrJRSStUxzpOM27d3dARKKaXUeXGOw9QA69fD9OmOjkIppZSqNudJxr/8As8+C5mZjo5EKaWUqhbnSMa//grffWdd105cSiml6hjnSMaHDsHq1dZ1TcZKKaXqGOdIxqGhp69rMlZKKVXHOEcybtv29PWjRx0Xh1JKKXUenOPUpoAA8PeHkSNh8mRHR6OUUkpVi3PsGYN1qDo+HoxxdCRKKaVUtThXMt66Vc81VkopVec4TzJu2xaSk2HePEdHopRSSlWL8yTjkh7VCQlQVOTYWJRSSqlqcL5kXFQEiYmOjUUppZSqBudLxqDnGiullKpTnCcZBwWBpye4ukJamqOjUUopparMOc4zBuuUpnbtICQErrrK0dEopZRSVeY8e8YAYWEQE+PoKJRSSqlqca5kHBoK+/fDq686OhKllFKqypwrGbdtC8XF8PXXjo5EKaWUqjLnSsYlPaoPH3ZsHEoppVQ1VCkZG2OGGmP2GmOijTFP2mh/1BgTZYzZboxZZYxpaf9Qq6AkGSclOeThlVJKqfNRaTI2xrgCc4BhQCdgjDGm01mL/QH0EJEIYAnwir0DrZLgYOvUptxcyMpySAhKKaVUdVVlz7gXEC0iB0QkH1gMjCy7gIisFpHsUzc3ACH2DbOKXFygaVPw8YH0dIeEoJRSSlVXVZJxMHCkzO24U/POZRzw7Z8J6k/p1g3atIFLLnFYCEoppVR1VCUZ2yoQLDYXNOY2oAdg89wiY8z9xpjNxpjNycnJVY+yOkJDIToaxGaISimlVK1TlWQcB5TdzQwBjp69kDHmCuAZYISI5NlakYj8V0R6iEiPxo0bn0+8lWvdGnJyYNasmlm/UkopZWdVScabgDBjTGtjTD3gFuCME3mNMZcCb2ElYsd2ZW7f3rpcv96hYSillFJVVWkyFpFC4GFgBbAb+FREdhljphpjRpxa7FWgPvCZMWarMcZxo260bWtdxsY6LASllFKqOqpUKEJElgPLz5r3XJnrV9g5rvPXsqVVNOLYMUdHopRSSlWJc43ABeDmBvXr66lNSiml6gznS8ZgDf7h5qY9qpVSStUJzpmMBw+2BgBRSiml6gDnzFihoXD8OKSmOjoSpZRSqlLOmYy9vKzL9993bBxKKaVUFThnMu7Y0brcts2xcSillFJV4JzJuEcP6/LAAcfGoZRSSlWBcyZjb2+rlGJ8vKMjUUoppSrlnMkYrDKK2oFLKaVUHeC8yTg0FPLzHR2FUkopVSnnTca33GJVbzp+3NGRKKWUUhVy3mRcUjAiOtqxcSillFKVcN5kfPiwdfnLL46NQymllKqE8ybjsDDrcudOx8ahlFJKVcJ5k3FoqHW5f79j41BKKaUq4bzJODjYujxyxLFxKKWUUpVw3mRcvz64u0NSkqMjUUoppSrkvMkYoE8fOHnSmpRSSqlayrmT8UMPWZc6RrVSSqlazLmTcZs21mVMjGPjUEoppSrg3Mn400+ty337HBuHUkopVQHnTsatWlmXeq6xUkqpWsy5k3HJ6U179jg2DqWUUqoCF0cyPnTIsXEopZRSFXDuZNy8uXWZnAx5eY6NRSmllDoH507GTZvCtdeCCMTGOjoapZRSyibnTsaurvDUU9Z1LaWolFKqlnLuZAzQuLF1qclYKaVULeX8yfjxx8HFRQf+UEopVWs5fzIODgZjdM9YKaVUrXVxJOOiIh2FSymlVK11cSRjsHpTFxY6NBSllFLKlosnGRcVwZEjjo1FKaWUssH5k3F4OEyaZF3X/42VUkrVQs6fjIOCYPJkq0f1G2/ooWqllFK1jvMnY4CUFGvwj2XLYNw4KC52dERKKaVUqYsjGd9wA+zdC1OnwnvvWYetRRwdlVJKKQWAm6MDuCCCgyE+Hj79FNLT4bXXICAAnn/e0ZEppZRSF1Ey/ukna/CPmTOthDxlCvj7w9//7ujolFJKXeQunmR89Kj1X7GLC7z9Nhw/DhMnWgn59tsdHaFSSqmLWJX+MzbGDDXG7DXGRBtjnrTRPtAY87sxptAYM9r+Yf5JzZtbvahTUqzbbm7w0UcweDDcfTcsXerY+JRSSl3UKk3GxhhXYA4wDOgEjDHGdDprscPAXcBH9g7QLoYPh2++gfr1T8/z9IQvv4Tu3eHmm2H1asfFp5RS6qJWlcPUvYBoETkAYIxZDIwEokoWEJHYU22185yh1q2hSRNYt65829tvw623wrXXwoMPQrNmVueuRo2shN2lizUvPR02by5//65drXOZU1Lgjz/Kt3fvbq0vIQF27Cjf3qsXNGxodTCLiirf3rev9SPi0CHb42sPGGDFeeCA7cpUgwaBu7t130OHyrdfcYX1X/ru3RAXd2abi4t19ACs2BMSzmyvVw8uu8y6vnUrJCef2e7lBf37W9c3b7a2YVm+vtCnj3V940Y4ceLMdj8/6NnTuv7rr3Dy5JntjRpBt27W9Z9/hry8M9ubNIGICOv66tXlzzFv3hw6d7auf/895bRoAe3bW6O3/fhj+fbWrSE01Hrcn38+s62oyPoLpGlT8PCA7dut7VxWhw5wySXW8964sfz6neG9l51t9dfYtw98fKypfn3w9oarrqr6e+/YsTO3n7O994qLISfH2l716kHHjlb7+bz3AMLCoFUra322vvcuhveePb73LiQRqXACRgPzy9y+HZh9jmUXAqMrWNf9wGZgc4sWLeSC2r9fxDqh6czpzTdF4uNFQkJstzdtKnLZZSKDB9tuf/FFke3bRRYutN3+2msi334r8uijtts3brTie/tt2+1RUSL5+SLPP2+7feVKkd27RR55xHb77Nkir74q0ru37faffxY5elRk/PjybV5ep7ff2LHl2wMDRXbtEtmwQaRv3/LtISEix49b97/88vLtkZGn19+zZ/n2jh2t57dhg0ibNuXbhw0TycsTSU+3Xqez2wcNsu67Y4eIr2/59nHjTj++MeXbH3nEajt50va2u+cekU8/FZkyxXZ7ZVO3biL33Sdy442222++WWTWLJG//912+xNPiHz1lcgzz9hunzBB5OWXRW691Xb7woXW++vFF223Dx1qbcMmTWy3v/CCyAcfiNx2m+32hg0rfv6+viItWogEBJRvM8Z6XD8/EReX8u0eHiL33y/y7LMi4eHl2wMCRCZNErn7but9auuxhw8XueEG248fGCgyYoTIVVeJeHuXb7/kEpGnn7Y+3/7+5dsHDhRZvFhk7lwr1rPbGzcW6dTp3N87JduvRQvbbcOHW5+Ndetst7/8cuXfeyIiv/9uu/39963vnaVLbbc/8IDIokXWNrDVvnSp9bn54APb7ZV97y1ZIrJ5s8jkybbbjxyx7v/CC7bbMzKs9scft92emipy7Jjt7zUPD+s7e+lSa7IjYLOI7fxorPZzM8bcCFwlIveeun070EtE/mZj2YXAMhFZUtmPgB49eshmW7+4akpODvz+e/n5bdpYvwBTUuDbbyE11bqemmpNeXmQlmb9ekpMtNZjL8ZYv6BDQqxfkV5e1v/Z6enWY6alQWZm+V/158PNDRo0sKbsbEhKOrPdw8P6td68ufWLNSfHmtzdrRhKYsnJgdzc6j12UJC13mbNrF/jwcFWPMnJ1vpiYqxfxwkJVR+QxcPD2tsoKqpeLCU8Pa091/btoW1bK57gYOu1CA629uCaN7fi3bsXvvjCijMmxvo1fvRo+XiCgk5PjRtbex9Nmljbevdua/tlZkJWlnWZm2u9Fvn51nYoeT7n+5zsycfHer2aNbOuZ2RYnR6PH7f2prKybN/P09O6T9OmEBlpfb68vKznlJ19+rlnZVl7p8ePW5+t1FTrvVavnjV5eFjb3tPTul9hoXVZ8tlIT7fWkZxsfYXaUr++tYfr6WntiZfEUVBgXbq5Wdv+xAnrsqAAXF1PP36DBtZlyXx3d+v7ICPDuk9GRtVH9HNzs56vr68VV8lRkwYNrL1ub29rO3t7W49XkhpSUqz3W2am9ZiZmdbjns3Pz3qvNWlirdvLy4o5K8v63srPt2LPz7cmFxdrKiiw5hcXnzmVvCftxdX19DZ0c7Nek8JC67lX5/vE1dW6b8OG1rYq+x1gzOnJ29u6zMqyHqPk+Z99BKMyfn72+f6lJESzRUR62GqrymHqOOCSMrdDgKPnWLb28vKCfv3O3R4YWLVe1YWF1ociPd36UGRknL5+4sTpD76tydPT+vI5etT2FB9vrb/kQxUaan2xl9xu0sR6c5R8oZR8gZS9LCy0PuCNGp05+fqeeZgvL886fFOSXEqmmBhrfv361n28vKwvxU6dTs+rX996DF9f25c+PlZi3b/fGg98/35r2rrV+sFTVkCAlQwHDrQuS6Zmzawv35IvoLMvMzOtL8qSQ59lv8x8fKy4i4utD2LJVPLBLJmSkqzn+8035X+cBAZa2z4m5vQH2MUF2rWz3kcREda4523aWAncz6/8YejzJWK9jmVf07OngoLTly4u1pdcSTIruV4yiVjPNzv7zOdfMi8/33qPlLzHgoKsbVuRoiLrfV/yo7VePevQaUCA/bZDVRQVWQkrMdF6nfz9rdfCz8/60q9JItbnPinJ+lGQnGxtUz8/K46SWEqSo73k51vfF4cOweHD5addu6zXz9PTetyS76SAAOu6p6e1bVxdrfdOyWXZ697eVsLz87N96eFx+sfVuT5jBQW2p5LvKw8PK75zfV9C+fdr2fXn5FR03MW6f8ljlGyLslPJtvDwOP0D7Ozrnp72e90qUZU9YzdgHzAYiAc2AbeKyC4byy6ktu4Zq9ohK8tKcIWFVtL183N0RJbMzNN7vtHR1mViovWDqCTxduxo3y9VpdRFpaI940qT8akVXA28DrgCC0TkRWPMVKzj318bY3oCXwL+QC6QICKdK1qnJmOllFIXkz97mBoRWQ4sP2vec2Wub8I6fK2UUkqparo4CkUopZRStZgmY6WUUsrBNBkrpZRSDqbJWCmllHIwTcZKKaWUg2kyVkoppRxMk7FSSinlYJqMlVJKKQfTZKyUUko5mCZjpZRSysE0GSullFIOpslYKaWUcrAqVW2qkQc2Jhk4ZMdVBgIpdlzfxUy3pf3otrQf3Zb2o9vSPqq7HVuKSGNbDQ5LxvZmjNl8rtJUqnp0W9qPbkv70W1pP7ot7cOe21EPUyullFIOpslYKaWUcjBnSsb/dXQATkS3pf3otrQf3Zb2o9vSPuy2HZ3mP2OllFKqrnKmPWOllFKqTnKKZGyMGWqM2WuMiTbGPOnoeOoSY8wCY0ySMWZnmXkBxpjvjTH7T136OzLGusAYc4kxZrUxZrcxZpcxZuKp+botq8kY42mM+c0Ys+3Utnzh1PzWxpiNp7blJ8aYeo6Ota4wxrgaY/4wxiw7dVu35XkwxsQaY3YYY7YaYzafmmeXz3idT8bGGFdgDjAM6ASMMcZ0cmxUdcpCYOhZ854EVolIGLDq1G1VsULgHyLSEegDPHTqfajbsvrygL+KSFcgEhhqjOkDvAy8dmpbpgPjHBhjXTMR2F3mtm7L83e5iESWOaXJLp/xOp+MgV5AtIgcEJF8YDEw0sEx1Rki8jOQdtbskcCiU9cXAddd0KDqIBE5JiK/n7qeifXFF4xuy2oTS9apm+6nJgH+Ciw5NV+3ZRUZY0KAa4D5p24bdFvak10+486QjIOBI2Vux52ap85fExE5BlaSAYIcHE+dYoxpBVwKbES35Xk5dVh1K5AEfA/EABkiUnhqEf2cV93rwBNA8anbjdBteb4EWGmM2WKMuf/UPLt8xt3sFKAjGRvztIu4cghjTH3gc+ARETlh7YSo6hKRIiDSGOMHfAl0tLXYhY2q7jHGDAeSRGSLMWZQyWwbi+q2rJp+InLUGBMEfG+M2WOvFTvDnnEccEmZ2yHAUQfF4iwSjTHNAE5dJjk4njrBGOOOlYg/FJEvTs3WbfkniEgGsAbrf3g/Y0zJDoR+zqumHzDCGBOL9RfeX7H2lHVbngcROXrqMgnrR2Iv7PQZ///27liljiAMw/D7owhBbBQ7CSLYegUWFmIRLBUCCt5EmtgIwmm9Ay0VTqM5F5AUlhYpItinyyVYfRa7IZLKA8Kwh/epZtkthh9mv52dYXcWwvgB2Ox3By4An4FJ4z4N3QQ46dsnwLeGfRmEfh3uEnhKcvHqlLWcUlWt9jNiquoDsEu3Bv8DOOgvs5ZvkORrkrUk63T3xu9JjrCWU6uqxapa+tsG9oBH3mmMz8RHP6rqE93T3hxwlWTUuEuDUVU3wA7d30f+AGfAHTAGPqJNj4kAAACISURBVAK/gcMk/2/y0itVtQ3cA7/4tzZ3SrdubC2nUFVbdBth5ugmDOMk51W1QTe7WwZ+AsdJntv1dFj619Rfkuxby+n1NbvtD+eB6ySjqlrhHcb4TISxJElDNguvqSVJGjTDWJKkxgxjSZIaM4wlSWrMMJYkqTHDWJKkxgxjSZIaM4wlSWrsBUHiT9tCB85gAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\"\"\"Code Here\n",
    "將結果繪出\n",
    "\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "color_bar = [\"r\", \"g\", \"b\", \"y\", \"m\", \"k\"]\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "for i, cond in enumerate(results.keys()):\n",
    "    plt.plot(range(len(results[cond]['train-loss'])),results[cond]['train-loss'], '-', label=cond, color=color_bar[i])\n",
    "    plt.plot(range(len(results[cond]['valid-loss'])),results[cond]['valid-loss'], '--', label=cond, color=color_bar[i])\n",
    "plt.title(\"Loss\")\n",
    "plt.ylim([0, 5])\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "for i, cond in enumerate(results.keys()):\n",
    "    plt.plot(range(len(results[cond]['train-acc'])),results[cond]['train-acc'], '-', label=cond, color=color_bar[i])\n",
    "    plt.plot(range(len(results[cond]['valid-acc'])),results[cond]['valid-acc'], '--', label=cond, color=color_bar[i])\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mlp(input_shape, output_units=10, num_neurons=[512, 256, 128], l1_ratio=1e-2,l2_ratio=1e-2):\n",
    "    input_layer = keras.layers.Input(input_shape)\n",
    "    \n",
    "    for i, n_units in enumerate(num_neurons):\n",
    "        if i == 0:\n",
    "            x = keras.layers.Dense(units=n_units, \n",
    "                                   activation=\"relu\", \n",
    "                                   name=\"hidden_layer\"+str(i+1), \n",
    "                                   kernel_regularizer=l1_l2(l1=l1_ratio,l2=l2_ratio))(input_layer)\n",
    "        else:\n",
    "            x = keras.layers.Dense(units=n_units, \n",
    "                                   activation=\"relu\", \n",
    "                                   name=\"hidden_layer\"+str(i+1),\n",
    "                                   kernel_regularizer=l1_l2(l1=l1_ratio,l2=l2_ratio))(x)\n",
    "    \n",
    "    out = keras.layers.Dense(units=output_units, activation=\"softmax\", name=\"output\")(x)\n",
    "    \n",
    "    model = keras.models.Model(inputs=[input_layer], outputs=[out])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 1e-3\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 256\n",
    "MOMENTUM = 0.95\n",
    "L1_EXP = [1e-2, 1e-4, 1e-8, 1e-12]\n",
    "L2_EXP = [1e-2, 1e-4, 1e-8, 1e-12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment with Regulizer = 0.010000 0.010000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 197.7631 - acc: 0.2462 - val_loss: 35.9433 - val_acc: 0.2618\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 15.9221 - acc: 0.1100 - val_loss: 5.1575 - val_acc: 0.1000\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 3.2191 - acc: 0.0994 - val_loss: 2.4723 - val_acc: 0.1000\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.4632 - acc: 0.0980 - val_loss: 2.4624 - val_acc: 0.1000\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.4624 - acc: 0.0977 - val_loss: 2.4624 - val_acc: 0.1000\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 2.4624 - acc: 0.0966 - val_loss: 2.4623 - val_acc: 0.1000\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 2.4624 - acc: 0.0970 - val_loss: 2.4624 - val_acc: 0.1000\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.4623 - acc: 0.0992 - val_loss: 2.4622 - val_acc: 0.1000\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.4623 - acc: 0.0984 - val_loss: 2.4622 - val_acc: 0.1000\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.4622 - acc: 0.0946 - val_loss: 2.4621 - val_acc: 0.1000\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.4622 - acc: 0.0990 - val_loss: 2.4621 - val_acc: 0.1000\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.4622 - acc: 0.0965 - val_loss: 2.4620 - val_acc: 0.1000\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.4621 - acc: 0.0976 - val_loss: 2.4620 - val_acc: 0.1000\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.4621 - acc: 0.0988 - val_loss: 2.4620 - val_acc: 0.1000\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.4621 - acc: 0.0975 - val_loss: 2.4620 - val_acc: 0.1000\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.4620 - acc: 0.0978 - val_loss: 2.4620 - val_acc: 0.1000\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 2.4620 - acc: 0.0961 - val_loss: 2.4620 - val_acc: 0.1000\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.4620 - acc: 0.0978 - val_loss: 2.4619 - val_acc: 0.1000\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 2.4620 - acc: 0.0986 - val_loss: 2.4620 - val_acc: 0.1000\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 2.4620 - acc: 0.0965 - val_loss: 2.4618 - val_acc: 0.1000\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 2.4620 - acc: 0.0975 - val_loss: 2.4619 - val_acc: 0.1000\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 2.4619 - acc: 0.0974 - val_loss: 2.4619 - val_acc: 0.1000\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 2.4619 - acc: 0.0984 - val_loss: 2.4619 - val_acc: 0.1000\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 2.4619 - acc: 0.0969 - val_loss: 2.4618 - val_acc: 0.1000\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 2.4619 - acc: 0.0960 - val_loss: 2.4619 - val_acc: 0.1000\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 2.4619 - acc: 0.0983 - val_loss: 2.4618 - val_acc: 0.1000\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 2.4619 - acc: 0.0979 - val_loss: 2.4618 - val_acc: 0.1000\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 2.4619 - acc: 0.0965 - val_loss: 2.4618 - val_acc: 0.1000\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 2.4619 - acc: 0.0966 - val_loss: 2.4617 - val_acc: 0.1000\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 2.4618 - acc: 0.0974 - val_loss: 2.4617 - val_acc: 0.1000\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 2.4618 - acc: 0.0971 - val_loss: 2.4618 - val_acc: 0.1000\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 2.4618 - acc: 0.0970 - val_loss: 2.4616 - val_acc: 0.1000\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 2.4618 - acc: 0.0964 - val_loss: 2.4616 - val_acc: 0.1000\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 2.4618 - acc: 0.0987 - val_loss: 2.4617 - val_acc: 0.1000\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 2.4617 - acc: 0.0978 - val_loss: 2.4616 - val_acc: 0.1000\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 2.4617 - acc: 0.0973 - val_loss: 2.4616 - val_acc: 0.1000\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 2.4617 - acc: 0.0977 - val_loss: 2.4616 - val_acc: 0.1000\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.4617 - acc: 0.0981 - val_loss: 2.4615 - val_acc: 0.1000\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 2.4616 - acc: 0.0982 - val_loss: 2.4616 - val_acc: 0.1000\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 2.4616 - acc: 0.0991 - val_loss: 2.4615 - val_acc: 0.1000\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.4616 - acc: 0.0975 - val_loss: 2.4614 - val_acc: 0.1000\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.4616 - acc: 0.0967 - val_loss: 2.4614 - val_acc: 0.1000\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.4615 - acc: 0.0965 - val_loss: 2.4614 - val_acc: 0.1000\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 2.4615 - acc: 0.0988 - val_loss: 2.4614 - val_acc: 0.1000\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 2.4615 - acc: 0.0972 - val_loss: 2.4613 - val_acc: 0.1000\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.4615 - acc: 0.0964 - val_loss: 2.4614 - val_acc: 0.1000\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.4615 - acc: 0.0982 - val_loss: 2.4613 - val_acc: 0.1000\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.4614 - acc: 0.0978 - val_loss: 2.4613 - val_acc: 0.1000\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.4614 - acc: 0.0976 - val_loss: 2.4613 - val_acc: 0.1000\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.4614 - acc: 0.0980 - val_loss: 2.4612 - val_acc: 0.1000\n",
      "Experiment with Regulizer = 0.010000 0.000100\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 198.7544 - acc: 0.2336 - val_loss: 41.0777 - val_acc: 0.2652\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 19.1030 - acc: 0.1158 - val_loss: 7.2648 - val_acc: 0.1000\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 4.0997 - acc: 0.1000 - val_loss: 2.6469 - val_acc: 0.1000\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.4860 - acc: 0.0979 - val_loss: 2.4624 - val_acc: 0.1000\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.4626 - acc: 0.0975 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 2.4626 - acc: 0.0971 - val_loss: 2.4624 - val_acc: 0.1000\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 2.4626 - acc: 0.0980 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.4626 - acc: 0.0969 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.4626 - acc: 0.0991 - val_loss: 2.4624 - val_acc: 0.1000\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.4626 - acc: 0.0971 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 2.4626 - acc: 0.0973 - val_loss: 2.4624 - val_acc: 0.1000\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 2.4626 - acc: 0.0974 - val_loss: 2.4624 - val_acc: 0.1000\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 2.4626 - acc: 0.0966 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 2.4626 - acc: 0.0967 - val_loss: 2.4624 - val_acc: 0.1000\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 2.4626 - acc: 0.0968 - val_loss: 2.4624 - val_acc: 0.1000\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 2.4626 - acc: 0.0983 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 2.4626 - acc: 0.0991 - val_loss: 2.4624 - val_acc: 0.1000\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 2.4626 - acc: 0.0991 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 2.4626 - acc: 0.0990 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.4626 - acc: 0.0985 - val_loss: 2.4624 - val_acc: 0.1000\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 2.4626 - acc: 0.0984 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.4626 - acc: 0.0955 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 2.4626 - acc: 0.0967 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 2.4626 - acc: 0.0977 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 2.4626 - acc: 0.0989 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 2.4626 - acc: 0.0975 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.4626 - acc: 0.0972 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.4626 - acc: 0.0978 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.4626 - acc: 0.0979 - val_loss: 2.4623 - val_acc: 0.1000\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.4626 - acc: 0.0978 - val_loss: 2.4624 - val_acc: 0.1000\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.4626 - acc: 0.0977 - val_loss: 2.4624 - val_acc: 0.1000\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 2.4626 - acc: 0.0965 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.4626 - acc: 0.0981 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.4626 - acc: 0.0989 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.4626 - acc: 0.0973 - val_loss: 2.4624 - val_acc: 0.1000\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.4626 - acc: 0.0966 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.4626 - acc: 0.0978 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.4626 - acc: 0.0969 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.4626 - acc: 0.0979 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.4626 - acc: 0.0984 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.4626 - acc: 0.0973 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.4626 - acc: 0.0977 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.4626 - acc: 0.0984 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 2.4626 - acc: 0.0974 - val_loss: 2.4624 - val_acc: 0.1000\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 2.4626 - acc: 0.0992 - val_loss: 2.4624 - val_acc: 0.1000\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 2.4626 - acc: 0.0982 - val_loss: 2.4624 - val_acc: 0.1000\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 2.4626 - acc: 0.0973 - val_loss: 2.4624 - val_acc: 0.1000\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.4626 - acc: 0.0976 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.4626 - acc: 0.0987 - val_loss: 2.4624 - val_acc: 0.1000\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 2.4626 - acc: 0.0981 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Experiment with Regulizer = 0.010000 0.000000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 3s 65us/step - loss: 198.7646 - acc: 0.2369 - val_loss: 41.2388 - val_acc: 0.2605\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 2s 48us/step - loss: 19.1887 - acc: 0.1169 - val_loss: 7.3223 - val_acc: 0.1000\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 4.1239 - acc: 0.1000 - val_loss: 2.6499 - val_acc: 0.1000\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 2.4863 - acc: 0.0981 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 2.4626 - acc: 0.0983 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 2.4626 - acc: 0.0967 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.4626 - acc: 0.0965 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.4626 - acc: 0.0975 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.4626 - acc: 0.0960 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.4626 - acc: 0.0989 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 2.4626 - acc: 0.0952 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.4626 - acc: 0.0967 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 2.4626 - acc: 0.0968 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.4626 - acc: 0.0980 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.4626 - acc: 0.0981 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.4626 - acc: 0.0981 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.4626 - acc: 0.0982 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.4626 - acc: 0.0971 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 2.4626 - acc: 0.0985 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 2.4626 - acc: 0.0955 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.4626 - acc: 0.1000 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.4626 - acc: 0.0988 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.4626 - acc: 0.0965 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.4626 - acc: 0.0963 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.4626 - acc: 0.0965 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 2.4626 - acc: 0.0968 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.4626 - acc: 0.0977 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.4626 - acc: 0.0973 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.4626 - acc: 0.0975 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.4626 - acc: 0.0982 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.4626 - acc: 0.0999 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.4626 - acc: 0.0982 - val_loss: 2.4624 - val_acc: 0.1000\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.4626 - acc: 0.0990 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.4626 - acc: 0.0978 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.4626 - acc: 0.0966 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.4626 - acc: 0.0975 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.4626 - acc: 0.0980 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 2.4626 - acc: 0.0976 - val_loss: 2.4624 - val_acc: 0.1000\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.4626 - acc: 0.0963 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.4626 - acc: 0.0960 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 2.4626 - acc: 0.0982 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.4626 - acc: 0.0984 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.4626 - acc: 0.0991 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 2.4626 - acc: 0.0978 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 2.4626 - acc: 0.0961 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.4626 - acc: 0.0983 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 2s 49us/step - loss: 2.4626 - acc: 0.0964 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 2.4626 - acc: 0.0978 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 2.4626 - acc: 0.0992 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.4626 - acc: 0.0974 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Experiment with Regulizer = 0.010000 0.000000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 198.9851 - acc: 0.2392 - val_loss: 41.2860 - val_acc: 0.2586\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 19.1959 - acc: 0.1196 - val_loss: 7.3284 - val_acc: 0.1000\n",
      "Epoch 3/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 3s 63us/step - loss: 4.1241 - acc: 0.0994 - val_loss: 2.6489 - val_acc: 0.1000\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 2.4864 - acc: 0.0970 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 2.4626 - acc: 0.0971 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 2.4626 - acc: 0.0967 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 2.4626 - acc: 0.0944 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 2.4626 - acc: 0.0996 - val_loss: 2.4624 - val_acc: 0.1000\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 2.4626 - acc: 0.0979 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 2.4626 - acc: 0.0988 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 2.4626 - acc: 0.0983 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 2.4626 - acc: 0.0980 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 2.4626 - acc: 0.0976 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 2.4626 - acc: 0.0981 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 2s 49us/step - loss: 2.4626 - acc: 0.0979 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 2s 49us/step - loss: 2.4626 - acc: 0.0988 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 2.4626 - acc: 0.0992 - val_loss: 2.4624 - val_acc: 0.1000\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.4626 - acc: 0.0976 - val_loss: 2.4624 - val_acc: 0.1000\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 2.4626 - acc: 0.1003 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 2.4626 - acc: 0.0975 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 2.4626 - acc: 0.0989 - val_loss: 2.4624 - val_acc: 0.1000\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 2.4626 - acc: 0.0980 - val_loss: 2.4624 - val_acc: 0.1000\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 2.4626 - acc: 0.0970 - val_loss: 2.4624 - val_acc: 0.1000\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 2s 49us/step - loss: 2.4626 - acc: 0.0979 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 2.4626 - acc: 0.0983 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 2.4626 - acc: 0.0965 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 2.4626 - acc: 0.0992 - val_loss: 2.4624 - val_acc: 0.1000\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 2.4626 - acc: 0.0976 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 2.4626 - acc: 0.0976 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 2.4626 - acc: 0.0979 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 2s 49us/step - loss: 2.4626 - acc: 0.0995 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 2.4626 - acc: 0.0982 - val_loss: 2.4624 - val_acc: 0.1000\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 2.4626 - acc: 0.0990 - val_loss: 2.4624 - val_acc: 0.1000\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 2.4626 - acc: 0.0983 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 2s 49us/step - loss: 2.4626 - acc: 0.0990 - val_loss: 2.4624 - val_acc: 0.1000\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 2.4626 - acc: 0.1000 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 2.4626 - acc: 0.0984 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 2.4626 - acc: 0.0988 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 2.4626 - acc: 0.0971 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 2.4626 - acc: 0.0976 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 2.4626 - acc: 0.0987 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 2.4626 - acc: 0.0970 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 2.4626 - acc: 0.0980 - val_loss: 2.4624 - val_acc: 0.1000\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 2.4626 - acc: 0.0981 - val_loss: 2.4624 - val_acc: 0.1000\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 2.4626 - acc: 0.0995 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 2.4626 - acc: 0.0964 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 2.4626 - acc: 0.0984 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 2.4626 - acc: 0.0980 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 4s 73us/step - loss: 2.4626 - acc: 0.0978 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 2s 50us/step - loss: 2.4626 - acc: 0.0985 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Experiment with Regulizer = 0.000100 0.010000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 18.8034 - acc: 0.2759 - val_loss: 17.3515 - val_acc: 0.3439\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 16.1356 - acc: 0.3598 - val_loss: 14.9723 - val_acc: 0.3729\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 13.9506 - acc: 0.3812 - val_loss: 12.9655 - val_acc: 0.3925\n",
      "Epoch 4/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 2s 44us/step - loss: 12.1034 - acc: 0.3968 - val_loss: 11.2681 - val_acc: 0.4048\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 10.5342 - acc: 0.4046 - val_loss: 9.8273 - val_acc: 0.3998\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 9.1976 - acc: 0.4101 - val_loss: 8.5932 - val_acc: 0.4157\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 8.0586 - acc: 0.4173 - val_loss: 7.5454 - val_acc: 0.4194\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 7.0896 - acc: 0.4198 - val_loss: 6.6488 - val_acc: 0.4254\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 6.2637 - acc: 0.4245 - val_loss: 5.8932 - val_acc: 0.4287\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 5.5592 - acc: 0.4297 - val_loss: 5.2415 - val_acc: 0.4304\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 4.9617 - acc: 0.4310 - val_loss: 4.6883 - val_acc: 0.4331\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 4.4512 - acc: 0.4348 - val_loss: 4.2230 - val_acc: 0.4359\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 4.0185 - acc: 0.4376 - val_loss: 3.8274 - val_acc: 0.4347\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 3.6533 - acc: 0.4389 - val_loss: 3.4877 - val_acc: 0.4410\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 3.3406 - acc: 0.4426 - val_loss: 3.2206 - val_acc: 0.4239\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 3.0769 - acc: 0.4444 - val_loss: 2.9677 - val_acc: 0.4412\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.8559 - acc: 0.4463 - val_loss: 2.7732 - val_acc: 0.4410\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.6723 - acc: 0.4466 - val_loss: 2.5919 - val_acc: 0.4502\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 2.5174 - acc: 0.4495 - val_loss: 2.4505 - val_acc: 0.4481\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 2.3897 - acc: 0.4493 - val_loss: 2.3417 - val_acc: 0.4512\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 2.2839 - acc: 0.4517 - val_loss: 2.2539 - val_acc: 0.4449\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.1969 - acc: 0.4528 - val_loss: 2.1655 - val_acc: 0.4472\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.1270 - acc: 0.4538 - val_loss: 2.1151 - val_acc: 0.4437\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 2.0706 - acc: 0.4534 - val_loss: 2.0569 - val_acc: 0.4465\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.0234 - acc: 0.4552 - val_loss: 2.0088 - val_acc: 0.4489\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 1.9844 - acc: 0.4556 - val_loss: 1.9742 - val_acc: 0.4542\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.9549 - acc: 0.4573 - val_loss: 1.9473 - val_acc: 0.4496\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.9298 - acc: 0.4573 - val_loss: 1.9240 - val_acc: 0.4578\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 1.9099 - acc: 0.4586 - val_loss: 1.9250 - val_acc: 0.4409\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 1.8919 - acc: 0.4613 - val_loss: 1.8963 - val_acc: 0.4534\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 1.8776 - acc: 0.4622 - val_loss: 1.8908 - val_acc: 0.4506\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.8643 - acc: 0.4615 - val_loss: 1.8768 - val_acc: 0.4526\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 1.8537 - acc: 0.4634 - val_loss: 1.8537 - val_acc: 0.4655\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 1.8395 - acc: 0.4644 - val_loss: 1.8614 - val_acc: 0.4546\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 1.8333 - acc: 0.4634 - val_loss: 1.8521 - val_acc: 0.4593\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 1.8231 - acc: 0.4674 - val_loss: 1.8489 - val_acc: 0.4596\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 2s 49us/step - loss: 1.8168 - acc: 0.4671 - val_loss: 1.8217 - val_acc: 0.4653\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 2s 49us/step - loss: 1.8095 - acc: 0.4690 - val_loss: 1.8278 - val_acc: 0.4550\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 2s 49us/step - loss: 1.8008 - acc: 0.4702 - val_loss: 1.8279 - val_acc: 0.4589\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.7974 - acc: 0.4708 - val_loss: 1.8122 - val_acc: 0.4650\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.7898 - acc: 0.4718 - val_loss: 1.8072 - val_acc: 0.4653\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 1.7867 - acc: 0.4724 - val_loss: 1.8406 - val_acc: 0.4490\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 1.7802 - acc: 0.4774 - val_loss: 1.7979 - val_acc: 0.4660\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 1.7748 - acc: 0.4762 - val_loss: 1.7988 - val_acc: 0.4693\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 1.7717 - acc: 0.4770 - val_loss: 1.8406 - val_acc: 0.4402\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 1.7682 - acc: 0.4764 - val_loss: 1.8695 - val_acc: 0.4351\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 1.7643 - acc: 0.4791 - val_loss: 1.7919 - val_acc: 0.4660\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.7591 - acc: 0.4789 - val_loss: 1.8147 - val_acc: 0.4636\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 1.7583 - acc: 0.4785 - val_loss: 1.7782 - val_acc: 0.4675\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.7536 - acc: 0.4832 - val_loss: 1.8129 - val_acc: 0.4479\n",
      "Experiment with Regulizer = 0.000100 0.000100\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 6.1419 - acc: 0.2696 - val_loss: 5.9399 - val_acc: 0.3441\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 5.8511 - acc: 0.3619 - val_loss: 5.7846 - val_acc: 0.3690\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 5.7008 - acc: 0.3926 - val_loss: 5.6345 - val_acc: 0.4026\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 5.5736 - acc: 0.4143 - val_loss: 5.5118 - val_acc: 0.4250\n",
      "Epoch 5/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 2s 49us/step - loss: 5.4580 - acc: 0.4279 - val_loss: 5.4089 - val_acc: 0.4360\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 5.3519 - acc: 0.4440 - val_loss: 5.3223 - val_acc: 0.4395\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 5.2511 - acc: 0.4540 - val_loss: 5.2056 - val_acc: 0.4531\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 5.1537 - acc: 0.4639 - val_loss: 5.1218 - val_acc: 0.4637\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 5.0622 - acc: 0.4737 - val_loss: 5.0461 - val_acc: 0.4698\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 4.9726 - acc: 0.4827 - val_loss: 4.9559 - val_acc: 0.4717\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 4.8862 - acc: 0.4896 - val_loss: 4.9061 - val_acc: 0.4671\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 4.8033 - acc: 0.4965 - val_loss: 4.8038 - val_acc: 0.4783\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 4.7216 - acc: 0.5026 - val_loss: 4.7329 - val_acc: 0.4856\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 4.6384 - acc: 0.5099 - val_loss: 4.6551 - val_acc: 0.4832\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 4.5617 - acc: 0.5136 - val_loss: 4.5794 - val_acc: 0.4957\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 4.4842 - acc: 0.5202 - val_loss: 4.5029 - val_acc: 0.4978\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 4.4078 - acc: 0.5254 - val_loss: 4.4755 - val_acc: 0.4871\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 4.3363 - acc: 0.5284 - val_loss: 4.4119 - val_acc: 0.4883\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 4.2640 - acc: 0.5336 - val_loss: 4.3074 - val_acc: 0.5029\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 4.1929 - acc: 0.5398 - val_loss: 4.2457 - val_acc: 0.5115\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 4.1235 - acc: 0.5452 - val_loss: 4.1733 - val_acc: 0.5133\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 4.0536 - acc: 0.5508 - val_loss: 4.1324 - val_acc: 0.5131\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 3.9877 - acc: 0.5527 - val_loss: 4.1323 - val_acc: 0.4910\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 3.9250 - acc: 0.5566 - val_loss: 4.0221 - val_acc: 0.5088\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 3.8589 - acc: 0.5603 - val_loss: 4.0082 - val_acc: 0.5014\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 3.7943 - acc: 0.5646 - val_loss: 3.8837 - val_acc: 0.5235\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 3.7333 - acc: 0.5684 - val_loss: 3.8569 - val_acc: 0.5184\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 3.6748 - acc: 0.5702 - val_loss: 3.8999 - val_acc: 0.4936\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 3.6113 - acc: 0.5758 - val_loss: 3.7419 - val_acc: 0.5136\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 3.5532 - acc: 0.5767 - val_loss: 3.7375 - val_acc: 0.5077\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 3.4983 - acc: 0.5807 - val_loss: 3.6430 - val_acc: 0.5206\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 3.4437 - acc: 0.5829 - val_loss: 3.7406 - val_acc: 0.4810\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 3.3862 - acc: 0.5875 - val_loss: 3.5367 - val_acc: 0.5239\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 3.3292 - acc: 0.5913 - val_loss: 3.5620 - val_acc: 0.5063\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 3.2767 - acc: 0.5931 - val_loss: 3.5847 - val_acc: 0.4893\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 3.2314 - acc: 0.5947 - val_loss: 3.3836 - val_acc: 0.5351\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 3.1723 - acc: 0.6011 - val_loss: 3.3894 - val_acc: 0.5100\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 3.1243 - acc: 0.6017 - val_loss: 3.4412 - val_acc: 0.4958\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 3.0799 - acc: 0.6030 - val_loss: 3.3512 - val_acc: 0.5003\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 3.0273 - acc: 0.6069 - val_loss: 3.2379 - val_acc: 0.5214\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 2.9824 - acc: 0.6081 - val_loss: 3.2455 - val_acc: 0.5149\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.9336 - acc: 0.6103 - val_loss: 3.1791 - val_acc: 0.5248\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.8913 - acc: 0.6113 - val_loss: 3.1327 - val_acc: 0.5189\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.8534 - acc: 0.6095 - val_loss: 3.1000 - val_acc: 0.5212\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 2.8075 - acc: 0.6143 - val_loss: 3.1070 - val_acc: 0.5111\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.7672 - acc: 0.6168 - val_loss: 3.1346 - val_acc: 0.5004\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 2.7228 - acc: 0.6201 - val_loss: 2.9577 - val_acc: 0.5343\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.6853 - acc: 0.6210 - val_loss: 3.0200 - val_acc: 0.5017\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 2.6496 - acc: 0.6207 - val_loss: 2.9073 - val_acc: 0.5238\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 2.6076 - acc: 0.6248 - val_loss: 2.9643 - val_acc: 0.5014\n",
      "Experiment with Regulizer = 0.000100 0.000000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 6.0109 - acc: 0.2745 - val_loss: 5.8179 - val_acc: 0.3440\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 5.7294 - acc: 0.3626 - val_loss: 5.6542 - val_acc: 0.3763\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 5.5854 - acc: 0.3913 - val_loss: 5.5291 - val_acc: 0.4019\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 5.4649 - acc: 0.4125 - val_loss: 5.4114 - val_acc: 0.4227\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 5.3556 - acc: 0.4282 - val_loss: 5.3128 - val_acc: 0.4252\n",
      "Epoch 6/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 2s 42us/step - loss: 5.2549 - acc: 0.4418 - val_loss: 5.2179 - val_acc: 0.4389\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 5.1582 - acc: 0.4530 - val_loss: 5.1222 - val_acc: 0.4489\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 5.0694 - acc: 0.4599 - val_loss: 5.0472 - val_acc: 0.4552\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 4.9812 - acc: 0.4721 - val_loss: 4.9685 - val_acc: 0.4532\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 4.8969 - acc: 0.4795 - val_loss: 4.8967 - val_acc: 0.4643\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 4.8144 - acc: 0.4864 - val_loss: 4.8146 - val_acc: 0.4725\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 4.7327 - acc: 0.4962 - val_loss: 4.7358 - val_acc: 0.4757\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 4.6541 - acc: 0.5013 - val_loss: 4.6605 - val_acc: 0.4810\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 4.5803 - acc: 0.5056 - val_loss: 4.6130 - val_acc: 0.4773\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 4.5057 - acc: 0.5133 - val_loss: 4.5234 - val_acc: 0.4901\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 4.4328 - acc: 0.5180 - val_loss: 4.5032 - val_acc: 0.4822\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 4.3619 - acc: 0.5238 - val_loss: 4.3939 - val_acc: 0.4966\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 4.2905 - acc: 0.5294 - val_loss: 4.3451 - val_acc: 0.4910\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 4.2237 - acc: 0.5327 - val_loss: 4.2951 - val_acc: 0.4939\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 4.1574 - acc: 0.5374 - val_loss: 4.2047 - val_acc: 0.5082\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 4.0902 - acc: 0.5443 - val_loss: 4.1544 - val_acc: 0.5061\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 4.0269 - acc: 0.5449 - val_loss: 4.0981 - val_acc: 0.5037\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 3.9630 - acc: 0.5519 - val_loss: 4.0416 - val_acc: 0.5169\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 3.9018 - acc: 0.5541 - val_loss: 3.9993 - val_acc: 0.5082\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 3.8419 - acc: 0.5582 - val_loss: 3.9312 - val_acc: 0.5099\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 3.7790 - acc: 0.5648 - val_loss: 3.8687 - val_acc: 0.5209\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 3.7221 - acc: 0.5659 - val_loss: 3.8312 - val_acc: 0.5178\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 3.6646 - acc: 0.5680 - val_loss: 3.8483 - val_acc: 0.4972\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 3.6114 - acc: 0.5728 - val_loss: 3.7303 - val_acc: 0.5185\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 3.5499 - acc: 0.5785 - val_loss: 3.6813 - val_acc: 0.5174\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 3.4985 - acc: 0.5790 - val_loss: 3.6299 - val_acc: 0.5204\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 3.4420 - acc: 0.5849 - val_loss: 3.5642 - val_acc: 0.5273\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 3.3900 - acc: 0.5866 - val_loss: 3.5390 - val_acc: 0.5207\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 3.3380 - acc: 0.5895 - val_loss: 3.6156 - val_acc: 0.4871\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 3.2867 - acc: 0.5919 - val_loss: 3.4936 - val_acc: 0.5104\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 3.2369 - acc: 0.5966 - val_loss: 3.4004 - val_acc: 0.5252\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 3.1903 - acc: 0.5959 - val_loss: 3.3612 - val_acc: 0.5195\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 3.1408 - acc: 0.6002 - val_loss: 3.2986 - val_acc: 0.5344\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 3.0929 - acc: 0.6036 - val_loss: 3.3258 - val_acc: 0.5118\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 3.0503 - acc: 0.6024 - val_loss: 3.3045 - val_acc: 0.5146\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 3.0080 - acc: 0.6053 - val_loss: 3.2192 - val_acc: 0.5189\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 2s 50us/step - loss: 2.9612 - acc: 0.6087 - val_loss: 3.1818 - val_acc: 0.5202\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 2.9180 - acc: 0.6104 - val_loss: 3.1194 - val_acc: 0.5295\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 2.8777 - acc: 0.6144 - val_loss: 3.1509 - val_acc: 0.5094\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.8280 - acc: 0.6179 - val_loss: 3.0623 - val_acc: 0.5310\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 2.7935 - acc: 0.6180 - val_loss: 2.9982 - val_acc: 0.5357\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.7577 - acc: 0.6173 - val_loss: 3.0231 - val_acc: 0.5198\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.7164 - acc: 0.6226 - val_loss: 2.9462 - val_acc: 0.5323\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 2.6798 - acc: 0.6233 - val_loss: 3.0248 - val_acc: 0.5015\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 2.6376 - acc: 0.6244 - val_loss: 2.8760 - val_acc: 0.5336\n",
      "Experiment with Regulizer = 0.000100 0.000000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 4s 70us/step - loss: 5.9977 - acc: 0.2806 - val_loss: 5.8073 - val_acc: 0.3411\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 5.7109 - acc: 0.3661 - val_loss: 5.6338 - val_acc: 0.3760\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 2s 49us/step - loss: 5.5632 - acc: 0.3969 - val_loss: 5.4981 - val_acc: 0.4127\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 5.4406 - acc: 0.4188 - val_loss: 5.3908 - val_acc: 0.4210\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 2s 49us/step - loss: 5.3346 - acc: 0.4340 - val_loss: 5.3012 - val_acc: 0.4324\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 5.2348 - acc: 0.4473 - val_loss: 5.1968 - val_acc: 0.4502\n",
      "Epoch 7/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 2s 47us/step - loss: 5.1427 - acc: 0.4551 - val_loss: 5.1092 - val_acc: 0.4540\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 5.0530 - acc: 0.4667 - val_loss: 5.0226 - val_acc: 0.4653\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 4.9668 - acc: 0.4732 - val_loss: 4.9555 - val_acc: 0.4621\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 4.8837 - acc: 0.4817 - val_loss: 4.8827 - val_acc: 0.4698\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 4.8037 - acc: 0.4885 - val_loss: 4.8048 - val_acc: 0.4748\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 4.7239 - acc: 0.4958 - val_loss: 4.7562 - val_acc: 0.4686\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 4.6465 - acc: 0.5019 - val_loss: 4.6638 - val_acc: 0.4816\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 4.5692 - acc: 0.5092 - val_loss: 4.5867 - val_acc: 0.4897\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 2s 49us/step - loss: 4.4969 - acc: 0.5145 - val_loss: 4.5459 - val_acc: 0.4831\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 4.4236 - acc: 0.5220 - val_loss: 4.4916 - val_acc: 0.4816\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 4.3530 - acc: 0.5264 - val_loss: 4.4164 - val_acc: 0.4883\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 4.2835 - acc: 0.5322 - val_loss: 4.3474 - val_acc: 0.4919\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 4.2160 - acc: 0.5340 - val_loss: 4.2685 - val_acc: 0.5082\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 4.1496 - acc: 0.5403 - val_loss: 4.2154 - val_acc: 0.5051\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 4.0836 - acc: 0.5470 - val_loss: 4.1753 - val_acc: 0.4964\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 2s 49us/step - loss: 4.0211 - acc: 0.5505 - val_loss: 4.0785 - val_acc: 0.5217\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 3.9546 - acc: 0.5555 - val_loss: 4.0555 - val_acc: 0.5085\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 3.8926 - acc: 0.5591 - val_loss: 3.9783 - val_acc: 0.5166\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 3.8319 - acc: 0.5647 - val_loss: 3.9270 - val_acc: 0.5211\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 3.7717 - acc: 0.5660 - val_loss: 3.8907 - val_acc: 0.5092\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 3.7134 - acc: 0.5698 - val_loss: 3.8443 - val_acc: 0.5127\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 3.6549 - acc: 0.5744 - val_loss: 3.8018 - val_acc: 0.5028\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 3.5983 - acc: 0.5786 - val_loss: 3.7242 - val_acc: 0.5192\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 3.5424 - acc: 0.5797 - val_loss: 3.7298 - val_acc: 0.5051\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 3.4896 - acc: 0.5839 - val_loss: 3.6355 - val_acc: 0.5220\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 3.4343 - acc: 0.5881 - val_loss: 3.5714 - val_acc: 0.5226\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 3.3804 - acc: 0.5915 - val_loss: 3.6152 - val_acc: 0.5022\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 3.3324 - acc: 0.5920 - val_loss: 3.5003 - val_acc: 0.5273\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 3.2802 - acc: 0.5961 - val_loss: 3.4912 - val_acc: 0.5186\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 3.2320 - acc: 0.5965 - val_loss: 3.5383 - val_acc: 0.4794\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 3.1793 - acc: 0.6017 - val_loss: 3.3788 - val_acc: 0.5216\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 3.1335 - acc: 0.6037 - val_loss: 3.3684 - val_acc: 0.5085\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 3.0855 - acc: 0.6070 - val_loss: 3.3134 - val_acc: 0.5207\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 3.0400 - acc: 0.6093 - val_loss: 3.2746 - val_acc: 0.5122\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 2.9976 - acc: 0.6104 - val_loss: 3.1934 - val_acc: 0.5294\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.9498 - acc: 0.6134 - val_loss: 3.1860 - val_acc: 0.5246\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 2.9107 - acc: 0.6140 - val_loss: 3.1082 - val_acc: 0.5355\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.8698 - acc: 0.6152 - val_loss: 3.1420 - val_acc: 0.5122\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 2.8306 - acc: 0.6172 - val_loss: 3.1192 - val_acc: 0.5163\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 2.7886 - acc: 0.6217 - val_loss: 3.0316 - val_acc: 0.5259\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 2.7471 - acc: 0.6228 - val_loss: 3.0575 - val_acc: 0.5123\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 2.7073 - acc: 0.6228 - val_loss: 3.0274 - val_acc: 0.5152\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.6757 - acc: 0.6242 - val_loss: 2.9889 - val_acc: 0.5095\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.6397 - acc: 0.6259 - val_loss: 3.1730 - val_acc: 0.4513\n",
      "Experiment with Regulizer = 0.000000 0.010000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 15.0438 - acc: 0.2871 - val_loss: 13.9124 - val_acc: 0.3497\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 12.9855 - acc: 0.3679 - val_loss: 12.1025 - val_acc: 0.3700\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 11.3141 - acc: 0.3905 - val_loss: 10.5604 - val_acc: 0.4033\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 9.9058 - acc: 0.4039 - val_loss: 9.2683 - val_acc: 0.4082\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 8.7080 - acc: 0.4126 - val_loss: 8.1670 - val_acc: 0.4128\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 7.6885 - acc: 0.4215 - val_loss: 7.2254 - val_acc: 0.4249\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 6.8184 - acc: 0.4285 - val_loss: 6.4251 - val_acc: 0.4294\n",
      "Epoch 8/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 2s 44us/step - loss: 6.0751 - acc: 0.4335 - val_loss: 5.7474 - val_acc: 0.4346\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 5.4423 - acc: 0.4386 - val_loss: 5.1632 - val_acc: 0.4348\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 4.9006 - acc: 0.4418 - val_loss: 4.6666 - val_acc: 0.4401\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 4.4374 - acc: 0.4472 - val_loss: 4.2432 - val_acc: 0.4368\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 4.0404 - acc: 0.4488 - val_loss: 3.8672 - val_acc: 0.4523\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 2s 49us/step - loss: 3.7008 - acc: 0.4557 - val_loss: 3.5574 - val_acc: 0.4497\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 3.4101 - acc: 0.4589 - val_loss: 3.2989 - val_acc: 0.4488\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 3.1608 - acc: 0.4615 - val_loss: 3.0573 - val_acc: 0.4554\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.9478 - acc: 0.4623 - val_loss: 2.8688 - val_acc: 0.4585\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.7651 - acc: 0.4685 - val_loss: 2.6912 - val_acc: 0.4620\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.6081 - acc: 0.4710 - val_loss: 2.5560 - val_acc: 0.4592\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.4738 - acc: 0.4725 - val_loss: 2.4279 - val_acc: 0.4641\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 2.3587 - acc: 0.4748 - val_loss: 2.3279 - val_acc: 0.4659\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 2.2602 - acc: 0.4740 - val_loss: 2.2549 - val_acc: 0.4654\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 2.1739 - acc: 0.4809 - val_loss: 2.1650 - val_acc: 0.4657\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 2.1002 - acc: 0.4813 - val_loss: 2.0860 - val_acc: 0.4710\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 2.0363 - acc: 0.4815 - val_loss: 2.0317 - val_acc: 0.4729\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 1.9813 - acc: 0.4859 - val_loss: 1.9901 - val_acc: 0.4720\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.9353 - acc: 0.4873 - val_loss: 1.9514 - val_acc: 0.4671\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.8936 - acc: 0.4887 - val_loss: 1.9243 - val_acc: 0.4655\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.8583 - acc: 0.4884 - val_loss: 1.8859 - val_acc: 0.4717\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.8273 - acc: 0.4925 - val_loss: 1.8463 - val_acc: 0.4774\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.8001 - acc: 0.4948 - val_loss: 1.8157 - val_acc: 0.4860\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.7781 - acc: 0.4963 - val_loss: 1.7925 - val_acc: 0.4868\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 1.7559 - acc: 0.4990 - val_loss: 1.7946 - val_acc: 0.4812\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 1.7390 - acc: 0.5015 - val_loss: 1.7931 - val_acc: 0.4729\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.7224 - acc: 0.5008 - val_loss: 1.8292 - val_acc: 0.4537\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.7094 - acc: 0.5032 - val_loss: 1.7329 - val_acc: 0.4967\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.6962 - acc: 0.5050 - val_loss: 1.7361 - val_acc: 0.4876\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 1.6857 - acc: 0.5063 - val_loss: 1.7355 - val_acc: 0.4881\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.6745 - acc: 0.5085 - val_loss: 1.7277 - val_acc: 0.4856\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 1.6672 - acc: 0.5099 - val_loss: 1.7385 - val_acc: 0.4776\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 1.6608 - acc: 0.5101 - val_loss: 1.7082 - val_acc: 0.4888\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 1.6530 - acc: 0.5145 - val_loss: 1.6862 - val_acc: 0.4985\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.6448 - acc: 0.5141 - val_loss: 1.6846 - val_acc: 0.4973\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.6395 - acc: 0.5165 - val_loss: 1.6914 - val_acc: 0.4954\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.6326 - acc: 0.5205 - val_loss: 1.7130 - val_acc: 0.4865\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.6300 - acc: 0.5179 - val_loss: 1.7186 - val_acc: 0.4841\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 1.6260 - acc: 0.5189 - val_loss: 1.6778 - val_acc: 0.4997\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.6200 - acc: 0.5223 - val_loss: 1.6842 - val_acc: 0.4920\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.6174 - acc: 0.5238 - val_loss: 1.7073 - val_acc: 0.4874\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 1.6147 - acc: 0.5213 - val_loss: 1.6728 - val_acc: 0.4985\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 2s 49us/step - loss: 1.6113 - acc: 0.5245 - val_loss: 1.7043 - val_acc: 0.4861\n",
      "Experiment with Regulizer = 0.000000 0.000100\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 2.1656 - acc: 0.2834 - val_loss: 2.0257 - val_acc: 0.3279\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 1.9523 - acc: 0.3618 - val_loss: 1.9114 - val_acc: 0.3749\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 1.8705 - acc: 0.3925 - val_loss: 1.8365 - val_acc: 0.4019\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 1.8080 - acc: 0.4156 - val_loss: 1.7899 - val_acc: 0.4199\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.7597 - acc: 0.4332 - val_loss: 1.7440 - val_acc: 0.4348\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.7209 - acc: 0.4458 - val_loss: 1.7218 - val_acc: 0.4403\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.6865 - acc: 0.4577 - val_loss: 1.6870 - val_acc: 0.4501\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.6570 - acc: 0.4665 - val_loss: 1.6725 - val_acc: 0.4573\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.6293 - acc: 0.4768 - val_loss: 1.6538 - val_acc: 0.4651\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 1.6054 - acc: 0.4840 - val_loss: 1.6415 - val_acc: 0.4647\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.5819 - acc: 0.4934 - val_loss: 1.6121 - val_acc: 0.4783\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 1.5591 - acc: 0.5019 - val_loss: 1.6022 - val_acc: 0.4780\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.5365 - acc: 0.5098 - val_loss: 1.5872 - val_acc: 0.4812\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 1.5175 - acc: 0.5157 - val_loss: 1.5790 - val_acc: 0.4867\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 1.4996 - acc: 0.5228 - val_loss: 1.5570 - val_acc: 0.4937\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 1.4807 - acc: 0.5291 - val_loss: 1.5685 - val_acc: 0.4964\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.4630 - acc: 0.5340 - val_loss: 1.5471 - val_acc: 0.5015\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 1.4462 - acc: 0.5409 - val_loss: 1.5291 - val_acc: 0.5092\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.4272 - acc: 0.5479 - val_loss: 1.5766 - val_acc: 0.4855\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.4115 - acc: 0.5516 - val_loss: 1.5720 - val_acc: 0.4899\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 1.3988 - acc: 0.5570 - val_loss: 1.5293 - val_acc: 0.5092\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.3856 - acc: 0.5632 - val_loss: 1.5168 - val_acc: 0.5141\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 2s 49us/step - loss: 1.3683 - acc: 0.5679 - val_loss: 1.5089 - val_acc: 0.5141\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 1.3564 - acc: 0.5714 - val_loss: 1.5256 - val_acc: 0.5102\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 1.3436 - acc: 0.5756 - val_loss: 1.5300 - val_acc: 0.5027\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 1.3266 - acc: 0.5835 - val_loss: 1.4772 - val_acc: 0.5238\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 2s 49us/step - loss: 1.3117 - acc: 0.5896 - val_loss: 1.4814 - val_acc: 0.5260\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 1.2994 - acc: 0.5940 - val_loss: 1.5069 - val_acc: 0.5187\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.2849 - acc: 0.5984 - val_loss: 1.5113 - val_acc: 0.5179\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.2741 - acc: 0.6015 - val_loss: 1.4806 - val_acc: 0.5287\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.2600 - acc: 0.6045 - val_loss: 1.5164 - val_acc: 0.5149\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 1.2461 - acc: 0.6100 - val_loss: 1.5303 - val_acc: 0.5127\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 1.2339 - acc: 0.6165 - val_loss: 1.4802 - val_acc: 0.5260\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.2214 - acc: 0.6207 - val_loss: 1.4885 - val_acc: 0.5270\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.2118 - acc: 0.6238 - val_loss: 1.4983 - val_acc: 0.5269\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.1965 - acc: 0.6296 - val_loss: 1.4978 - val_acc: 0.5297\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.1843 - acc: 0.6315 - val_loss: 1.4847 - val_acc: 0.5326\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 1.1745 - acc: 0.6361 - val_loss: 1.5107 - val_acc: 0.5312\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.1650 - acc: 0.6394 - val_loss: 1.5264 - val_acc: 0.5219\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 1.1455 - acc: 0.6472 - val_loss: 1.6540 - val_acc: 0.4845\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 1.1368 - acc: 0.6482 - val_loss: 1.5125 - val_acc: 0.5226\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 1.1217 - acc: 0.6561 - val_loss: 1.5875 - val_acc: 0.5079\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.1112 - acc: 0.6576 - val_loss: 1.6011 - val_acc: 0.5121\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 1.1044 - acc: 0.6623 - val_loss: 1.5285 - val_acc: 0.5192\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 1.0881 - acc: 0.6661 - val_loss: 1.5260 - val_acc: 0.5264\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 1.0770 - acc: 0.6720 - val_loss: 1.5203 - val_acc: 0.5316\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 1.0624 - acc: 0.6763 - val_loss: 1.6280 - val_acc: 0.5117\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 1.0572 - acc: 0.6780 - val_loss: 1.5080 - val_acc: 0.5340\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.0419 - acc: 0.6861 - val_loss: 1.5343 - val_acc: 0.5308\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 1.0308 - acc: 0.6882 - val_loss: 1.5101 - val_acc: 0.5341\n",
      "Experiment with Regulizer = 0.000000 0.000000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 2.0064 - acc: 0.2892 - val_loss: 1.8429 - val_acc: 0.3559\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.7917 - acc: 0.3730 - val_loss: 1.7456 - val_acc: 0.3946\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.7130 - acc: 0.3998 - val_loss: 1.6797 - val_acc: 0.4100\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 1.6605 - acc: 0.4195 - val_loss: 1.6395 - val_acc: 0.4203\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.6148 - acc: 0.4369 - val_loss: 1.6030 - val_acc: 0.4356\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 1.5760 - acc: 0.4486 - val_loss: 1.5723 - val_acc: 0.4504\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 1.5414 - acc: 0.4611 - val_loss: 1.5460 - val_acc: 0.4579\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.5114 - acc: 0.4723 - val_loss: 1.5347 - val_acc: 0.4559\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 1.4851 - acc: 0.4813 - val_loss: 1.5127 - val_acc: 0.4710\n",
      "Epoch 10/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 2s 46us/step - loss: 1.4596 - acc: 0.4887 - val_loss: 1.4876 - val_acc: 0.4724\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 1.4343 - acc: 0.4980 - val_loss: 1.4766 - val_acc: 0.4780\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.4122 - acc: 0.5060 - val_loss: 1.4748 - val_acc: 0.4802\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 1.3902 - acc: 0.5127 - val_loss: 1.4398 - val_acc: 0.4913\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 1.3695 - acc: 0.5190 - val_loss: 1.4266 - val_acc: 0.4914\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 2s 49us/step - loss: 1.3492 - acc: 0.5266 - val_loss: 1.4326 - val_acc: 0.4935\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 2s 49us/step - loss: 1.3298 - acc: 0.5342 - val_loss: 1.4430 - val_acc: 0.4914\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 1.3117 - acc: 0.5396 - val_loss: 1.4042 - val_acc: 0.5101\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 1.2958 - acc: 0.5444 - val_loss: 1.3929 - val_acc: 0.5050\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 1.2800 - acc: 0.5508 - val_loss: 1.3839 - val_acc: 0.5146\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 1.2641 - acc: 0.5571 - val_loss: 1.3906 - val_acc: 0.5124\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 1.2492 - acc: 0.5603 - val_loss: 1.3847 - val_acc: 0.5082\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.2333 - acc: 0.5665 - val_loss: 1.3563 - val_acc: 0.5201\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 1.2181 - acc: 0.5743 - val_loss: 1.3591 - val_acc: 0.5208\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.2016 - acc: 0.5788 - val_loss: 1.3946 - val_acc: 0.5024\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 1.1888 - acc: 0.5822 - val_loss: 1.3778 - val_acc: 0.5161\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 1.1754 - acc: 0.5874 - val_loss: 1.3889 - val_acc: 0.5106\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 1.1612 - acc: 0.5927 - val_loss: 1.3675 - val_acc: 0.5109\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 1.1478 - acc: 0.5962 - val_loss: 1.3639 - val_acc: 0.5156\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.1371 - acc: 0.6011 - val_loss: 1.3457 - val_acc: 0.5255\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.1201 - acc: 0.6067 - val_loss: 1.3644 - val_acc: 0.5156\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.1100 - acc: 0.6119 - val_loss: 1.3877 - val_acc: 0.5099\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.0981 - acc: 0.6138 - val_loss: 1.3546 - val_acc: 0.5249\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.0845 - acc: 0.6209 - val_loss: 1.3431 - val_acc: 0.5278\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 1.0710 - acc: 0.6239 - val_loss: 1.3360 - val_acc: 0.5292\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.0573 - acc: 0.6293 - val_loss: 1.4154 - val_acc: 0.5015\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 1.0474 - acc: 0.6345 - val_loss: 1.3496 - val_acc: 0.5278\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.0336 - acc: 0.6373 - val_loss: 1.3425 - val_acc: 0.5306\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.0195 - acc: 0.6414 - val_loss: 1.3902 - val_acc: 0.5200\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.0065 - acc: 0.6444 - val_loss: 1.4668 - val_acc: 0.4983\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 0.9979 - acc: 0.6503 - val_loss: 1.3391 - val_acc: 0.5390\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 0.9803 - acc: 0.6590 - val_loss: 1.4482 - val_acc: 0.5045\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 0.9748 - acc: 0.6579 - val_loss: 1.3507 - val_acc: 0.5290\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 0.9549 - acc: 0.6667 - val_loss: 1.3420 - val_acc: 0.5390\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 0.9456 - acc: 0.6689 - val_loss: 1.3481 - val_acc: 0.5387\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 0.9352 - acc: 0.6751 - val_loss: 1.3579 - val_acc: 0.5311\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 0.9240 - acc: 0.6786 - val_loss: 1.5113 - val_acc: 0.5048\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 0.9108 - acc: 0.6815 - val_loss: 1.4879 - val_acc: 0.5049\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.8991 - acc: 0.6858 - val_loss: 1.3585 - val_acc: 0.5330\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 0.8881 - acc: 0.6917 - val_loss: 1.3641 - val_acc: 0.5331\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.8701 - acc: 0.6978 - val_loss: 1.3713 - val_acc: 0.5321\n",
      "Experiment with Regulizer = 0.000000 0.000000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 2.0213 - acc: 0.2786 - val_loss: 1.8508 - val_acc: 0.3523\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 1.7925 - acc: 0.3708 - val_loss: 1.7445 - val_acc: 0.3953\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 1.7153 - acc: 0.3969 - val_loss: 1.6853 - val_acc: 0.4074\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 1.6605 - acc: 0.4184 - val_loss: 1.6435 - val_acc: 0.4235\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 1.6138 - acc: 0.4350 - val_loss: 1.6034 - val_acc: 0.4384\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 1.5767 - acc: 0.4473 - val_loss: 1.5769 - val_acc: 0.4459\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.5453 - acc: 0.4611 - val_loss: 1.5462 - val_acc: 0.4541\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.5153 - acc: 0.4692 - val_loss: 1.5322 - val_acc: 0.4587\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 1.4894 - acc: 0.4782 - val_loss: 1.4989 - val_acc: 0.4729\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 1.4641 - acc: 0.4861 - val_loss: 1.4925 - val_acc: 0.4681\n",
      "Epoch 11/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 2s 47us/step - loss: 1.4411 - acc: 0.4939 - val_loss: 1.4900 - val_acc: 0.4736\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 1.4188 - acc: 0.5025 - val_loss: 1.4536 - val_acc: 0.4832\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.3949 - acc: 0.5093 - val_loss: 1.4448 - val_acc: 0.4873\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 1.3743 - acc: 0.5156 - val_loss: 1.4348 - val_acc: 0.4907\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 1.3540 - acc: 0.5246 - val_loss: 1.4122 - val_acc: 0.4984\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 1.3330 - acc: 0.5318 - val_loss: 1.4029 - val_acc: 0.5032\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 1.3161 - acc: 0.5383 - val_loss: 1.4131 - val_acc: 0.4953\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.2998 - acc: 0.5432 - val_loss: 1.4083 - val_acc: 0.5050\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.2807 - acc: 0.5486 - val_loss: 1.3874 - val_acc: 0.5010\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 1.2651 - acc: 0.5553 - val_loss: 1.4080 - val_acc: 0.5022\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 1.2498 - acc: 0.5609 - val_loss: 1.3676 - val_acc: 0.5164\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.2338 - acc: 0.5669 - val_loss: 1.3696 - val_acc: 0.5168\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 1.2165 - acc: 0.5717 - val_loss: 1.3703 - val_acc: 0.5137\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 1.2026 - acc: 0.5776 - val_loss: 1.3599 - val_acc: 0.5241\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.1885 - acc: 0.5830 - val_loss: 1.3673 - val_acc: 0.5155\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 1.1734 - acc: 0.5884 - val_loss: 1.3612 - val_acc: 0.5203\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 1.1596 - acc: 0.5938 - val_loss: 1.3634 - val_acc: 0.5222\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 1.1468 - acc: 0.5958 - val_loss: 1.3652 - val_acc: 0.5200\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.1348 - acc: 0.6011 - val_loss: 1.3334 - val_acc: 0.5318\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.1204 - acc: 0.6068 - val_loss: 1.3925 - val_acc: 0.5165\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.1066 - acc: 0.6114 - val_loss: 1.3402 - val_acc: 0.5307\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.0911 - acc: 0.6169 - val_loss: 1.3360 - val_acc: 0.5302\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 1.0792 - acc: 0.6209 - val_loss: 1.3411 - val_acc: 0.5351\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 1.0702 - acc: 0.6230 - val_loss: 1.3895 - val_acc: 0.5170\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 1.0549 - acc: 0.6308 - val_loss: 1.3557 - val_acc: 0.5285\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.0427 - acc: 0.6364 - val_loss: 1.4146 - val_acc: 0.5161\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.0311 - acc: 0.6399 - val_loss: 1.3728 - val_acc: 0.5190\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 2s 50us/step - loss: 1.0170 - acc: 0.6431 - val_loss: 1.3556 - val_acc: 0.5303\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.0034 - acc: 0.6486 - val_loss: 1.4110 - val_acc: 0.5150\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 0.9893 - acc: 0.6534 - val_loss: 1.3847 - val_acc: 0.5201\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.9806 - acc: 0.6558 - val_loss: 1.4407 - val_acc: 0.5158\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 0.9683 - acc: 0.6622 - val_loss: 1.4117 - val_acc: 0.5171\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 0.9581 - acc: 0.6644 - val_loss: 1.4455 - val_acc: 0.5114\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 0.9403 - acc: 0.6688 - val_loss: 1.3781 - val_acc: 0.5312\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.9307 - acc: 0.6753 - val_loss: 1.3824 - val_acc: 0.5237\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 0.9235 - acc: 0.6762 - val_loss: 1.3769 - val_acc: 0.5348\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 0.9085 - acc: 0.6798 - val_loss: 1.3518 - val_acc: 0.5370\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 0.8945 - acc: 0.6873 - val_loss: 1.4686 - val_acc: 0.5090\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.8867 - acc: 0.6890 - val_loss: 1.4888 - val_acc: 0.5095\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 0.8732 - acc: 0.6941 - val_loss: 1.4134 - val_acc: 0.5227\n",
      "Experiment with Regulizer = 0.000000 0.010000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 15.1242 - acc: 0.2747 - val_loss: 13.9700 - val_acc: 0.3500\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 13.0344 - acc: 0.3616 - val_loss: 12.1457 - val_acc: 0.3662\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 11.3587 - acc: 0.3837 - val_loss: 10.6120 - val_acc: 0.3882\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 9.9430 - acc: 0.3979 - val_loss: 9.3045 - val_acc: 0.4051\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 8.7413 - acc: 0.4080 - val_loss: 8.2003 - val_acc: 0.4141\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 7.7167 - acc: 0.4174 - val_loss: 7.2578 - val_acc: 0.4204\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 6.8427 - acc: 0.4258 - val_loss: 6.4601 - val_acc: 0.4202\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 6.0979 - acc: 0.4313 - val_loss: 5.7680 - val_acc: 0.4298\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 5.4611 - acc: 0.4375 - val_loss: 5.1825 - val_acc: 0.4294\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 4.9177 - acc: 0.4397 - val_loss: 4.6762 - val_acc: 0.4432\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 4.4512 - acc: 0.4456 - val_loss: 4.2467 - val_acc: 0.4408\n",
      "Epoch 12/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 2s 43us/step - loss: 4.0541 - acc: 0.4489 - val_loss: 3.8830 - val_acc: 0.4455\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 3.7126 - acc: 0.4542 - val_loss: 3.5661 - val_acc: 0.4498\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 3.4206 - acc: 0.4577 - val_loss: 3.2954 - val_acc: 0.4525\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 3.1697 - acc: 0.4621 - val_loss: 3.0832 - val_acc: 0.4501\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 2.9553 - acc: 0.4640 - val_loss: 2.8753 - val_acc: 0.4538\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 2.7701 - acc: 0.4666 - val_loss: 2.7050 - val_acc: 0.4631\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.6127 - acc: 0.4699 - val_loss: 2.5807 - val_acc: 0.4514\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 2.4771 - acc: 0.4729 - val_loss: 2.4471 - val_acc: 0.4584\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 2.3616 - acc: 0.4765 - val_loss: 2.3453 - val_acc: 0.4643\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 2.2598 - acc: 0.4786 - val_loss: 2.2338 - val_acc: 0.4677\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.1739 - acc: 0.4817 - val_loss: 2.1807 - val_acc: 0.4675\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 2.1004 - acc: 0.4836 - val_loss: 2.0941 - val_acc: 0.4708\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 2.0364 - acc: 0.4866 - val_loss: 2.0351 - val_acc: 0.4673\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 1.9812 - acc: 0.4881 - val_loss: 1.9822 - val_acc: 0.4795\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 1.9343 - acc: 0.4911 - val_loss: 1.9442 - val_acc: 0.4805\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 1.8911 - acc: 0.4921 - val_loss: 1.9174 - val_acc: 0.4761\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 1.8556 - acc: 0.4960 - val_loss: 1.8665 - val_acc: 0.4839\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 1.8252 - acc: 0.4974 - val_loss: 1.8510 - val_acc: 0.4801\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 1.7998 - acc: 0.4980 - val_loss: 1.8169 - val_acc: 0.4889\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.7734 - acc: 0.4995 - val_loss: 1.8150 - val_acc: 0.4759\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.7538 - acc: 0.5015 - val_loss: 1.8313 - val_acc: 0.4686\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.7362 - acc: 0.5021 - val_loss: 1.7828 - val_acc: 0.4866\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.7197 - acc: 0.5049 - val_loss: 1.7810 - val_acc: 0.4780\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 1.7063 - acc: 0.5050 - val_loss: 1.7408 - val_acc: 0.4939\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 1.6936 - acc: 0.5093 - val_loss: 1.7330 - val_acc: 0.4946\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.6822 - acc: 0.5102 - val_loss: 1.7721 - val_acc: 0.4696\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 1.6724 - acc: 0.5111 - val_loss: 1.7141 - val_acc: 0.4974\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.6635 - acc: 0.5129 - val_loss: 1.7120 - val_acc: 0.4954\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.6570 - acc: 0.5131 - val_loss: 1.6891 - val_acc: 0.5002\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 1.6495 - acc: 0.5165 - val_loss: 1.6909 - val_acc: 0.5026\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 1.6431 - acc: 0.5186 - val_loss: 1.7073 - val_acc: 0.4842\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 1.6370 - acc: 0.5188 - val_loss: 1.7325 - val_acc: 0.4795\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 1.6323 - acc: 0.5205 - val_loss: 1.7309 - val_acc: 0.4721\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 1.6266 - acc: 0.5207 - val_loss: 1.6751 - val_acc: 0.5006\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 1.6234 - acc: 0.5213 - val_loss: 1.6816 - val_acc: 0.5020\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 1.6167 - acc: 0.5257 - val_loss: 1.6897 - val_acc: 0.4887\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.6147 - acc: 0.5249 - val_loss: 1.6691 - val_acc: 0.5060\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 1.6111 - acc: 0.5275 - val_loss: 1.6828 - val_acc: 0.4972\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 1.6082 - acc: 0.5261 - val_loss: 1.6676 - val_acc: 0.5096\n",
      "Experiment with Regulizer = 0.000000 0.000100\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 2.1640 - acc: 0.2803 - val_loss: 2.0016 - val_acc: 0.3508\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.9509 - acc: 0.3633 - val_loss: 1.9046 - val_acc: 0.3791\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 1.8700 - acc: 0.3917 - val_loss: 1.8329 - val_acc: 0.4052\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 1.8137 - acc: 0.4138 - val_loss: 1.7898 - val_acc: 0.4197\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.7675 - acc: 0.4294 - val_loss: 1.7521 - val_acc: 0.4273\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 1.7273 - acc: 0.4443 - val_loss: 1.7367 - val_acc: 0.4362\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.6936 - acc: 0.4555 - val_loss: 1.6976 - val_acc: 0.4498\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.6627 - acc: 0.4641 - val_loss: 1.6716 - val_acc: 0.4616\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.6334 - acc: 0.4737 - val_loss: 1.6648 - val_acc: 0.4612\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.6110 - acc: 0.4830 - val_loss: 1.6308 - val_acc: 0.4691\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.5854 - acc: 0.4935 - val_loss: 1.6307 - val_acc: 0.4659\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 1.5627 - acc: 0.4999 - val_loss: 1.5987 - val_acc: 0.4819\n",
      "Epoch 13/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.5432 - acc: 0.5055 - val_loss: 1.5910 - val_acc: 0.4855\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.5226 - acc: 0.5134 - val_loss: 1.5872 - val_acc: 0.4882\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.5026 - acc: 0.5214 - val_loss: 1.5649 - val_acc: 0.4957\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.4855 - acc: 0.5268 - val_loss: 1.5636 - val_acc: 0.4932\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 1.4658 - acc: 0.5326 - val_loss: 1.5481 - val_acc: 0.5007\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.4492 - acc: 0.5391 - val_loss: 1.5413 - val_acc: 0.5012\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 1.4324 - acc: 0.5459 - val_loss: 1.5544 - val_acc: 0.4975\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.4171 - acc: 0.5514 - val_loss: 1.5677 - val_acc: 0.4981\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 1.4017 - acc: 0.5551 - val_loss: 1.5309 - val_acc: 0.5037\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 1.3850 - acc: 0.5607 - val_loss: 1.5609 - val_acc: 0.4930\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 1.3712 - acc: 0.5664 - val_loss: 1.5103 - val_acc: 0.5158\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 1.3563 - acc: 0.5724 - val_loss: 1.5087 - val_acc: 0.5177\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.3420 - acc: 0.5765 - val_loss: 1.5012 - val_acc: 0.5190\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.3265 - acc: 0.5817 - val_loss: 1.4986 - val_acc: 0.5193\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.3126 - acc: 0.5851 - val_loss: 1.5625 - val_acc: 0.5017\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 1.2996 - acc: 0.5914 - val_loss: 1.5490 - val_acc: 0.5075\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.2885 - acc: 0.5944 - val_loss: 1.4828 - val_acc: 0.5258\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.2726 - acc: 0.5997 - val_loss: 1.5376 - val_acc: 0.5108\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.2622 - acc: 0.6032 - val_loss: 1.5204 - val_acc: 0.5231\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.2469 - acc: 0.6096 - val_loss: 1.4966 - val_acc: 0.5240\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.2334 - acc: 0.6161 - val_loss: 1.4886 - val_acc: 0.5237\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.2218 - acc: 0.6204 - val_loss: 1.5243 - val_acc: 0.5117\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.2100 - acc: 0.6244 - val_loss: 1.5336 - val_acc: 0.5159\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 1.1978 - acc: 0.6292 - val_loss: 1.4764 - val_acc: 0.5358\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 1.1868 - acc: 0.6285 - val_loss: 1.4641 - val_acc: 0.5339\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 1.1702 - acc: 0.6395 - val_loss: 1.5379 - val_acc: 0.5108\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 2s 49us/step - loss: 1.1613 - acc: 0.6417 - val_loss: 1.5264 - val_acc: 0.5186\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 1.1506 - acc: 0.6458 - val_loss: 1.5053 - val_acc: 0.5238\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 1.1359 - acc: 0.6506 - val_loss: 1.5420 - val_acc: 0.5175\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 1.1268 - acc: 0.6510 - val_loss: 1.5051 - val_acc: 0.5221\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 3s 60us/step - loss: 1.1118 - acc: 0.6592 - val_loss: 1.5683 - val_acc: 0.5095\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 3s 63us/step - loss: 1.1016 - acc: 0.6601 - val_loss: 1.5030 - val_acc: 0.5299\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.0873 - acc: 0.6672 - val_loss: 1.5002 - val_acc: 0.5336\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 1.0798 - acc: 0.6711 - val_loss: 1.5379 - val_acc: 0.5239\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 1.0636 - acc: 0.6749 - val_loss: 1.5090 - val_acc: 0.5274\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 1.0536 - acc: 0.6797 - val_loss: 1.6666 - val_acc: 0.4946\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 1.0460 - acc: 0.6818 - val_loss: 1.5555 - val_acc: 0.5223\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 1.0333 - acc: 0.6869 - val_loss: 1.5257 - val_acc: 0.5333\n",
      "Experiment with Regulizer = 0.000000 0.000000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 2.0580 - acc: 0.2609 - val_loss: 1.8917 - val_acc: 0.3371\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 1.8256 - acc: 0.3584 - val_loss: 1.7791 - val_acc: 0.3761\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 1.7354 - acc: 0.3925 - val_loss: 1.7157 - val_acc: 0.3963\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 1.6768 - acc: 0.4135 - val_loss: 1.6597 - val_acc: 0.4155\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 1.6310 - acc: 0.4301 - val_loss: 1.6197 - val_acc: 0.4368\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.5913 - acc: 0.4440 - val_loss: 1.5858 - val_acc: 0.4395\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 1.5587 - acc: 0.4541 - val_loss: 1.5561 - val_acc: 0.4526\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 1.5268 - acc: 0.4665 - val_loss: 1.5457 - val_acc: 0.4531\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 1.5002 - acc: 0.4765 - val_loss: 1.5414 - val_acc: 0.4498\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 1.4722 - acc: 0.4836 - val_loss: 1.4929 - val_acc: 0.4720\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 1.4487 - acc: 0.4918 - val_loss: 1.4905 - val_acc: 0.4739\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.4250 - acc: 0.4999 - val_loss: 1.4631 - val_acc: 0.4844\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 2s 50us/step - loss: 1.4037 - acc: 0.5074 - val_loss: 1.4513 - val_acc: 0.4893\n",
      "Epoch 14/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 2s 50us/step - loss: 1.3819 - acc: 0.5138 - val_loss: 1.4488 - val_acc: 0.4889\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.3633 - acc: 0.5206 - val_loss: 1.4336 - val_acc: 0.4962\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.3446 - acc: 0.5277 - val_loss: 1.4257 - val_acc: 0.4941\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.3247 - acc: 0.5359 - val_loss: 1.4096 - val_acc: 0.5042\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.3077 - acc: 0.5389 - val_loss: 1.4129 - val_acc: 0.5014\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.2917 - acc: 0.5440 - val_loss: 1.4000 - val_acc: 0.5011\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.2738 - acc: 0.5493 - val_loss: 1.3907 - val_acc: 0.5059\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 1.2591 - acc: 0.5554 - val_loss: 1.3680 - val_acc: 0.5111\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 1.2408 - acc: 0.5622 - val_loss: 1.3783 - val_acc: 0.5105\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 1.2249 - acc: 0.5686 - val_loss: 1.3644 - val_acc: 0.5144\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.2113 - acc: 0.5716 - val_loss: 1.4071 - val_acc: 0.5049\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.1955 - acc: 0.5801 - val_loss: 1.3578 - val_acc: 0.5210\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.1806 - acc: 0.5841 - val_loss: 1.3581 - val_acc: 0.5244\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.1674 - acc: 0.5868 - val_loss: 1.3592 - val_acc: 0.5229\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.1552 - acc: 0.5919 - val_loss: 1.3724 - val_acc: 0.5128\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.1411 - acc: 0.5986 - val_loss: 1.3859 - val_acc: 0.5096\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.1273 - acc: 0.6027 - val_loss: 1.3439 - val_acc: 0.5273\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.1148 - acc: 0.6061 - val_loss: 1.3579 - val_acc: 0.5228\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.0997 - acc: 0.6131 - val_loss: 1.3605 - val_acc: 0.5216\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.0860 - acc: 0.6179 - val_loss: 1.3362 - val_acc: 0.5314\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.0730 - acc: 0.6211 - val_loss: 1.4093 - val_acc: 0.5062\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 1.0628 - acc: 0.6258 - val_loss: 1.3327 - val_acc: 0.5312\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.0500 - acc: 0.6312 - val_loss: 1.3712 - val_acc: 0.5241\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.0389 - acc: 0.6344 - val_loss: 1.4346 - val_acc: 0.5065\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.0253 - acc: 0.6405 - val_loss: 1.3578 - val_acc: 0.5277\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.0080 - acc: 0.6459 - val_loss: 1.4892 - val_acc: 0.4993\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 0.9963 - acc: 0.6493 - val_loss: 1.3925 - val_acc: 0.5179\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 0.9875 - acc: 0.6525 - val_loss: 1.3728 - val_acc: 0.5266\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 0.9748 - acc: 0.6577 - val_loss: 1.3721 - val_acc: 0.5270\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 0.9624 - acc: 0.6644 - val_loss: 1.3675 - val_acc: 0.5289\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 0.9462 - acc: 0.6694 - val_loss: 1.3764 - val_acc: 0.5260\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 0.9379 - acc: 0.6713 - val_loss: 1.4213 - val_acc: 0.5201\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 0.9235 - acc: 0.6770 - val_loss: 1.3482 - val_acc: 0.5416\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 0.9156 - acc: 0.6798 - val_loss: 1.3791 - val_acc: 0.5266\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 0.9032 - acc: 0.6813 - val_loss: 1.4342 - val_acc: 0.5202\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 0.8891 - acc: 0.6889 - val_loss: 1.4156 - val_acc: 0.5251\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 0.8803 - acc: 0.6925 - val_loss: 1.4817 - val_acc: 0.5115\n",
      "Experiment with Regulizer = 0.000000 0.000000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 2.0231 - acc: 0.2724 - val_loss: 1.8721 - val_acc: 0.3438\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 1.8010 - acc: 0.3713 - val_loss: 1.7481 - val_acc: 0.3855\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.7187 - acc: 0.3982 - val_loss: 1.6931 - val_acc: 0.4078\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.6617 - acc: 0.4190 - val_loss: 1.6368 - val_acc: 0.4202\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.6147 - acc: 0.4353 - val_loss: 1.5969 - val_acc: 0.4357\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.5771 - acc: 0.4466 - val_loss: 1.5668 - val_acc: 0.4540\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.5429 - acc: 0.4609 - val_loss: 1.5524 - val_acc: 0.4510\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.5123 - acc: 0.4694 - val_loss: 1.5435 - val_acc: 0.4527\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.4845 - acc: 0.4791 - val_loss: 1.4995 - val_acc: 0.4686\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.4601 - acc: 0.4870 - val_loss: 1.4769 - val_acc: 0.4769\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.4333 - acc: 0.4971 - val_loss: 1.4616 - val_acc: 0.4801\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.4099 - acc: 0.5056 - val_loss: 1.4442 - val_acc: 0.4885\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.3882 - acc: 0.5126 - val_loss: 1.4750 - val_acc: 0.4752\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.3676 - acc: 0.5183 - val_loss: 1.4134 - val_acc: 0.4976\n",
      "Epoch 15/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.3497 - acc: 0.5250 - val_loss: 1.4176 - val_acc: 0.5009\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.3301 - acc: 0.5317 - val_loss: 1.4128 - val_acc: 0.5003\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.3123 - acc: 0.5353 - val_loss: 1.4084 - val_acc: 0.5004\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.2934 - acc: 0.5450 - val_loss: 1.3923 - val_acc: 0.5009\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.2780 - acc: 0.5490 - val_loss: 1.3757 - val_acc: 0.5113\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.2632 - acc: 0.5553 - val_loss: 1.3775 - val_acc: 0.5114\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.2485 - acc: 0.5604 - val_loss: 1.3522 - val_acc: 0.5228\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.2318 - acc: 0.5652 - val_loss: 1.3426 - val_acc: 0.5205\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 1.2145 - acc: 0.5736 - val_loss: 1.3397 - val_acc: 0.5223\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 1.1989 - acc: 0.5783 - val_loss: 1.3840 - val_acc: 0.5187\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 1.1873 - acc: 0.5828 - val_loss: 1.3736 - val_acc: 0.5111\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 1.1706 - acc: 0.5882 - val_loss: 1.3514 - val_acc: 0.5149\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.1585 - acc: 0.5912 - val_loss: 1.3403 - val_acc: 0.5222\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 1.1441 - acc: 0.5998 - val_loss: 1.3388 - val_acc: 0.5273\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 1.1305 - acc: 0.6038 - val_loss: 1.3596 - val_acc: 0.5187\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 1.1161 - acc: 0.6065 - val_loss: 1.3474 - val_acc: 0.5239\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 1.1051 - acc: 0.6124 - val_loss: 1.3250 - val_acc: 0.5259\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.0901 - acc: 0.6190 - val_loss: 1.3943 - val_acc: 0.5158\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 1.0768 - acc: 0.6227 - val_loss: 1.3239 - val_acc: 0.5346\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.0619 - acc: 0.6275 - val_loss: 1.3390 - val_acc: 0.5261\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.0523 - acc: 0.6297 - val_loss: 1.3522 - val_acc: 0.5273\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.0400 - acc: 0.6356 - val_loss: 1.3311 - val_acc: 0.5365\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.0258 - acc: 0.6393 - val_loss: 1.3462 - val_acc: 0.5273\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.0132 - acc: 0.6458 - val_loss: 1.3776 - val_acc: 0.5218\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.0041 - acc: 0.6484 - val_loss: 1.3551 - val_acc: 0.5265\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 0.9911 - acc: 0.6522 - val_loss: 1.4271 - val_acc: 0.5067\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 0.9744 - acc: 0.6559 - val_loss: 1.3143 - val_acc: 0.5425\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 0.9639 - acc: 0.6613 - val_loss: 1.3993 - val_acc: 0.5229\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 0.9511 - acc: 0.6668 - val_loss: 1.4708 - val_acc: 0.5042\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 0.9432 - acc: 0.6682 - val_loss: 1.3421 - val_acc: 0.5362\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.9251 - acc: 0.6738 - val_loss: 1.4873 - val_acc: 0.5079\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 0.9144 - acc: 0.6794 - val_loss: 1.4975 - val_acc: 0.4987\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.9040 - acc: 0.6844 - val_loss: 1.3889 - val_acc: 0.5321\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.8967 - acc: 0.6868 - val_loss: 1.4091 - val_acc: 0.5213\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.8802 - acc: 0.6901 - val_loss: 1.5661 - val_acc: 0.4889\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.8704 - acc: 0.6941 - val_loss: 1.3604 - val_acc: 0.5455\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\"\"\"Code Here\n",
    "撰寫你的訓練流程並將結果用 dictionary 紀錄\n",
    "\"\"\"\n",
    "for regulizer_ratio1 in L1_EXP:\n",
    "    for regulizer_ratio2 in L2_EXP:\n",
    "        keras.backend.clear_session() # 把舊的 Graph 清掉\n",
    "        print(\"Experiment with Regulizer = %.6f %.6f\" % (regulizer_ratio1 , regulizer_ratio2))\n",
    "        model = build_mlp(input_shape=x_train.shape[1:], l1_ratio=regulizer_ratio1, l2_ratio=regulizer_ratio2)\n",
    "        model.summary()\n",
    "        optimizer = keras.optimizers.SGD(lr=LEARNING_RATE, nesterov=True, momentum=MOMENTUM)\n",
    "        model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=optimizer)\n",
    "\n",
    "        model.fit(x_train, y_train, \n",
    "                  epochs=EPOCHS, \n",
    "                  batch_size=BATCH_SIZE, \n",
    "                  validation_data=(x_test, y_test), \n",
    "                  shuffle=True)\n",
    "\n",
    "        # Collect results\n",
    "        train_loss = model.history.history[\"loss\"]\n",
    "        valid_loss = model.history.history[\"val_loss\"]\n",
    "        train_acc = model.history.history[\"acc\"]\n",
    "        valid_acc = model.history.history[\"val_acc\"]\n",
    "\n",
    "        exp_name_tag = \"exp-l2-%s\" % str(regulizer_ratio)\n",
    "        results[exp_name_tag] = {'train-loss': train_loss,\n",
    "                                 'valid-loss': valid_loss,\n",
    "                                 'train-acc': train_acc,\n",
    "                                 'valid-acc': valid_acc}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
